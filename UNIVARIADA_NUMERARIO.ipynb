{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d88659d",
   "metadata": {},
   "source": [
    "\n",
    "## Análise de Drift Univariada - Método Conformal\n",
    "### Modelo Numerários\n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e3159b",
   "metadata": {},
   "source": [
    "Este notebook implementa a detecção de drift usando o método conformal baseado na diferença entre valores preditos e reais.\n",
    "**Referência**: https://arxiv.org/abs/2102.10439"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e9efc7c",
   "metadata": {},
   "source": [
    "### 1. Importação de Bibliotecas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3cf7a6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm import tqdm\n",
    "from datetime import datetime, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "386bc632",
   "metadata": {},
   "source": [
    "### 2. Configurações de visualização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6cc062d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette(\"husl\")\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "plt.rcParams['font.size'] = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec610d2",
   "metadata": {},
   "source": [
    "### 3. Funções do Método Conformal"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371f179c",
   "metadata": {},
   "source": [
    " Implementações baseadas no código wine.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd9b09ca",
   "metadata": {},
   "source": [
    "#### 3.1 Cálculo dos p-valores conformais baseados na diferença entre valores reais e preditos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f13f3d0",
   "metadata": {},
   "source": [
    "    Args:\n",
    "        y_true: Valores reais\n",
    "        y_pred: Valores preditos\n",
    "        rtol, atol: Tolerâncias para comparação de valores\n",
    "        \n",
    "    Returns:\n",
    "        p_det: P-valores determinísticos\n",
    "        p_rnd: P-valores randomizados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ba13a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calcular_pvalores_pred(y_true, y_pred, rtol=1e-03, atol=1e-03):\n",
    "\n",
    "    # Calcula os scores de não-conformidade (erro)\n",
    "    alpha = y_true - y_pred\n",
    "    N = len(alpha)\n",
    "    p_det = np.zeros(N)\n",
    "    p_rnd = np.zeros(N)\n",
    "    \n",
    "    for n in tqdm(range(N), desc=\"Calculando p-valores\"):\n",
    "        alpha_n = alpha[n]\n",
    "        # Considera todos os scores até o momento atual (incluindo o atual)\n",
    "        anteriores = alpha[:n+1]\n",
    "        \n",
    "        if n == 0:\n",
    "            p_det[0] = 1\n",
    "            p_rnd[0] = 1\n",
    "            continue\n",
    "        \n",
    "        # P-valor determinístico: proporção de scores maiores ou iguais\n",
    "        p_det[n] = np.mean(anteriores >= alpha_n)\n",
    "        \n",
    "        # P-valor randomizado: trata empates de forma aleatória\n",
    "        countG = np.sum(anteriores > alpha_n)\n",
    "        countE = np.sum(np.isclose(anteriores, alpha_n, rtol=rtol, atol=atol))\n",
    "        u = np.random.uniform() if countE > 0 else 0\n",
    "        p_rnd[n] = (countG + u * countE) / (n + 1)\n",
    "    \n",
    "    return p_det, p_rnd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d998f7",
   "metadata": {},
   "source": [
    "#### 3.2 Cálculo do Power Martingale a partir de p-valores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc29845",
   "metadata": {},
   "source": [
    "    Args:\n",
    "        p_values: Array de p-valores\n",
    "        epsilon: Parâmetro do power martingale (0 < epsilon < 1)\n",
    "        \n",
    "    Returns:\n",
    "        M: Array com valores do martingale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4eebe70d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def power_martingale(p_values, epsilon=0.92):\n",
    "\n",
    "    # Evita p-valores zero (proteção contra log(0))\n",
    "    p_values = np.maximum(p_values, 1e-10)\n",
    "    \n",
    "    # Power martingale: M_n = ∏(epsilon * p_i^(epsilon-1))\n",
    "    betting = epsilon * (p_values ** (epsilon - 1))\n",
    "    M = np.cumprod(betting)\n",
    "    \n",
    "    return M\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3604379",
   "metadata": {},
   "source": [
    "#### 3.3 Simple Jumper Martingale"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e417ce6",
   "metadata": {},
   "source": [
    "    Args:\n",
    "        p_values: Array de p-valores (0 < p <= 1)\n",
    "        J: Probabilidade de mudar de estratégia\n",
    "        \n",
    "    Returns:\n",
    "        capital: Array com valores do martingale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f37ac815",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def simple_jumper_martingale(p_values, J=0.01):\n",
    "\n",
    "\n",
    "    n = len(p_values)\n",
    "    capital = np.zeros(n + 1)\n",
    "    capital[0] = 1.0  # S0 = 1\n",
    "    \n",
    "    # Capital inicial para cada estratégia (3 estratégias: conservadora, neutra, agressiva)\n",
    "    C = {epsilon: 1/3 for epsilon in [-1, 0, 1]}  # C_{-1}, C_0, C_1\n",
    "    \n",
    "    for i in range(n):\n",
    "        # Etapa 1: transição (Markov chain) - possibilidade de mudar de estratégia\n",
    "        C_new = {}\n",
    "        total = sum(C.values())\n",
    "        for epsilon in [-1, 0, 1]:\n",
    "            # (1-J) mantém estratégia atual, J/3 muda para qualquer estratégia\n",
    "            C_new[epsilon] = (1 - J) * C[epsilon] + J * total / 3\n",
    "        \n",
    "        # Etapa 2: update capital com função de aposta\n",
    "        p = p_values[i]\n",
    "        for epsilon in [-1, 0, 1]:\n",
    "            # Função de aposta: f(p) = 1 + ε(p - 0.5)\n",
    "            f_eps = 1 + epsilon * (p - 0.5)\n",
    "            C_new[epsilon] *= f_eps\n",
    "        \n",
    "        # Soma dos capitais de todas as estratégias\n",
    "        capital[i + 1] = sum(C_new.values())\n",
    "        C = C_new\n",
    "    \n",
    "    return capital[1:]  # Retorna S_1 até S_n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1098486",
   "metadata": {},
   "source": [
    "##### Calculando o score por outros métodos\n",
    "tirar aspas para rodar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "15369746",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nef calcular_score_nao_conformidade(y_true, y_pred, metodo=\\'absoluto\\', janela_historico=30, epsilon=1e-8):\\n\\n    # Calcula diferentes tipos de scores de não-conformidade.\\n\\n    #Args:\\n     #   y_true: Valores reais\\n     #   y_pred: Valores preditos\\n     #   metodo: Tipo de score (\\'absoluto\\', \\'relativo\\', \\'z_score\\', \\'mad\\', \\'dist_min\\', \\'dist_media\\')\\n     #   janela_historico: Tamanho da janela para métodos que usam histórico\\n     #   epsilon: Termo para evitar divisão por zero\\n\\n  #  Returns:\\n   #     scores: Array com scores de não-conformidade\\n\\n    # Erro bruto (base para vários métodos)\\n    erros = y_true - y_pred\\n    n = len(erros)\\n    scores = np.zeros(n)\\n\\n    if metodo == \\'absoluto\\':\\n        # A. Erro Absoluto Simples\\n        scores = np.abs(erros)\\n\\n    elif metodo == \\'relativo\\':\\n        # B. Erro Relativo\\n        scores = np.abs(erros) / (np.abs(y_true) + epsilon)\\n\\n    elif metodo == \\'z_score\\':\\n        # C. Erro Padronizado (Z-score)\\n        for i in range(n):\\n            if i < janela_historico:\\n                # Para início da série, usar dados disponíveis\\n                if i > 0:\\n                    std_hist = np.std(erros[:i])\\n                    if std_hist > 0:\\n                        scores[i] = np.abs(erros[i]) / std_hist\\n                    else:\\n                        scores[i] = np.abs(erros[i])\\n                else:\\n                    scores[i] = 0\\n            else:\\n                # Usar janela deslizante\\n                janela_erros = erros[i-janela_historico:i]\\n                std_hist = np.std(janela_erros)\\n                if std_hist > 0:\\n                    scores[i] = np.abs(erros[i]) / std_hist\\n                else:\\n                    scores[i] = np.abs(erros[i])\\n\\n    elif metodo == \\'mad\\':\\n        # D. Erro Normalizado por MAD\\n        for i in range(n):\\n            if i < janela_historico:\\n                if i > 0:\\n                    janela_erros = erros[:i]\\n                    mad = np.median(np.abs(janela_erros - np.median(janela_erros)))\\n                    # Fator 1.4826 converte MAD para estimativa de desvio padrão\\n                    scores[i] = np.abs(erros[i]) / (1.4826 * mad + epsilon)\\n                else:\\n                    scores[i] = 0\\n            else:\\n                janela_erros = erros[i-janela_historico:i]\\n                mad = np.median(np.abs(janela_erros - np.median(janela_erros)))\\n                scores[i] = np.abs(erros[i]) / (1.4826 * mad + epsilon)\\n\\n    elif metodo == \\'dist_min\\':\\n        # E. Distância Mínima (como no conformal_whine)\\n        for i in range(n):\\n            if i > 0:\\n                # Distância mínima aos erros anteriores\\n                historico = erros[:i]\\n                distancias = np.abs(erros[i] - historico)\\n                scores[i] = np.min(distancias)\\n            else:\\n                scores[i] = 0\\n\\n    elif metodo == \\'dist_media\\':\\n        # F. Distância Média\\n        for i in range(n):\\n            if i > 0:\\n                # Distância média aos erros anteriores\\n                historico = erros[:i]\\n                distancias = np.abs(erros[i] - historico)\\n                scores[i] = np.mean(distancias)\\n            else:\\n                scores[i] = 0\\n\\n    else:\\n        raise ValueError(f\"Método \\'{metodo}\\' não reconhecido. Use: \\'absoluto\\', \\'relativo\\', \\'z_score\\', \\'mad\\', \\'dist_min\\', \\'dist_media\\'\")\\n\\n    return scores\\n\\n\\ndef calcular_pvalores_pred_com_score(y_true, y_pred, metodo_score=\\'absoluto\\', \\n                                    janela_historico=30, rtol=1e-03, atol=1e-03):\\n\\n#    Calcula p-valores conformais usando diferentes scores de não-conformidade.\\n\\n #   Esta é uma versão da função # Calcular p-valores conformais p_det, p_rnd = calcular_pvalores_pred(y_real, y_pred) \\n # que permite escolher o método de score\\n\\n\\n    # Calcular scores de não-conformidade usando o método escolhido\\n    scores = calcular_score_nao_conformidade(y_true, y_pred, metodo=metodo_score, \\n                                            janela_historico=janela_historico)\\n\\n    N = len(scores)\\n    p_det = np.zeros(N)\\n    p_rnd = np.zeros(N)\\n\\n    for n in tqdm(range(N), desc=f\"Calculando p-valores ({metodo_score})\"):\\n        score_n = scores[n]\\n        # Considera todos os scores até o momento atual (incluindo o atual)\\n        anteriores = scores[:n+1]\\n\\n        if n == 0:\\n            p_det[0] = 1\\n            p_rnd[0] = 1\\n            continue\\n\\n        # P-valor determinístico: proporção de scores maiores ou iguais\\n        p_det[n] = np.mean(anteriores >= score_n)\\n\\n        # P-valor randomizado: trata empates de forma aleatória\\n        countG = np.sum(anteriores > score_n)\\n        countE = np.sum(np.isclose(anteriores, score_n, rtol=rtol, atol=atol))\\n        u = np.random.uniform() if countE > 0 else 0\\n        p_rnd[n] = (countG + u * countE) / (n + 1)\\n\\n    return p_det, p_rnd\\n\\n'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "ef calcular_score_nao_conformidade(y_true, y_pred, metodo='absoluto', janela_historico=30, epsilon=1e-8):\n",
    "    \n",
    "    # Calcula diferentes tipos de scores de não-conformidade.\n",
    "    \n",
    "    #Args:\n",
    "     #   y_true: Valores reais\n",
    "     #   y_pred: Valores preditos\n",
    "     #   metodo: Tipo de score ('absoluto', 'relativo', 'z_score', 'mad', 'dist_min', 'dist_media')\n",
    "     #   janela_historico: Tamanho da janela para métodos que usam histórico\n",
    "     #   epsilon: Termo para evitar divisão por zero\n",
    "        \n",
    "  #  Returns:\n",
    "   #     scores: Array com scores de não-conformidade\n",
    "        \n",
    "    # Erro bruto (base para vários métodos)\n",
    "    erros = y_true - y_pred\n",
    "    n = len(erros)\n",
    "    scores = np.zeros(n)\n",
    "    \n",
    "    if metodo == 'absoluto':\n",
    "        # A. Erro Absoluto Simples\n",
    "        scores = np.abs(erros)\n",
    "        \n",
    "    elif metodo == 'relativo':\n",
    "        # B. Erro Relativo\n",
    "        scores = np.abs(erros) / (np.abs(y_true) + epsilon)\n",
    "        \n",
    "    elif metodo == 'z_score':\n",
    "        # C. Erro Padronizado (Z-score)\n",
    "        for i in range(n):\n",
    "            if i < janela_historico:\n",
    "                # Para início da série, usar dados disponíveis\n",
    "                if i > 0:\n",
    "                    std_hist = np.std(erros[:i])\n",
    "                    if std_hist > 0:\n",
    "                        scores[i] = np.abs(erros[i]) / std_hist\n",
    "                    else:\n",
    "                        scores[i] = np.abs(erros[i])\n",
    "                else:\n",
    "                    scores[i] = 0\n",
    "            else:\n",
    "                # Usar janela deslizante\n",
    "                janela_erros = erros[i-janela_historico:i]\n",
    "                std_hist = np.std(janela_erros)\n",
    "                if std_hist > 0:\n",
    "                    scores[i] = np.abs(erros[i]) / std_hist\n",
    "                else:\n",
    "                    scores[i] = np.abs(erros[i])\n",
    "                    \n",
    "    elif metodo == 'mad':\n",
    "        # D. Erro Normalizado por MAD\n",
    "        for i in range(n):\n",
    "            if i < janela_historico:\n",
    "                if i > 0:\n",
    "                    janela_erros = erros[:i]\n",
    "                    mad = np.median(np.abs(janela_erros - np.median(janela_erros)))\n",
    "                    # Fator 1.4826 converte MAD para estimativa de desvio padrão\n",
    "                    scores[i] = np.abs(erros[i]) / (1.4826 * mad + epsilon)\n",
    "                else:\n",
    "                    scores[i] = 0\n",
    "            else:\n",
    "                janela_erros = erros[i-janela_historico:i]\n",
    "                mad = np.median(np.abs(janela_erros - np.median(janela_erros)))\n",
    "                scores[i] = np.abs(erros[i]) / (1.4826 * mad + epsilon)\n",
    "                \n",
    "    elif metodo == 'dist_min':\n",
    "        # E. Distância Mínima (como no conformal_whine)\n",
    "        for i in range(n):\n",
    "            if i > 0:\n",
    "                # Distância mínima aos erros anteriores\n",
    "                historico = erros[:i]\n",
    "                distancias = np.abs(erros[i] - historico)\n",
    "                scores[i] = np.min(distancias)\n",
    "            else:\n",
    "                scores[i] = 0\n",
    "                \n",
    "    elif metodo == 'dist_media':\n",
    "        # F. Distância Média\n",
    "        for i in range(n):\n",
    "            if i > 0:\n",
    "                # Distância média aos erros anteriores\n",
    "                historico = erros[:i]\n",
    "                distancias = np.abs(erros[i] - historico)\n",
    "                scores[i] = np.mean(distancias)\n",
    "            else:\n",
    "                scores[i] = 0\n",
    "    \n",
    "    else:\n",
    "        raise ValueError(f\"Método '{metodo}' não reconhecido. Use: 'absoluto', 'relativo', 'z_score', 'mad', 'dist_min', 'dist_media'\")\n",
    "    \n",
    "    return scores\n",
    "\n",
    "\n",
    "def calcular_pvalores_pred_com_score(y_true, y_pred, metodo_score='absoluto', \n",
    "                                    janela_historico=30, rtol=1e-03, atol=1e-03):\n",
    "\n",
    "#    Calcula p-valores conformais usando diferentes scores de não-conformidade.\n",
    "    \n",
    " #   Esta é uma versão da função # Calcular p-valores conformais p_det, p_rnd = calcular_pvalores_pred(y_real, y_pred) \n",
    " # que permite escolher o método de score\n",
    "  \n",
    "    \n",
    "    # Calcular scores de não-conformidade usando o método escolhido\n",
    "    scores = calcular_score_nao_conformidade(y_true, y_pred, metodo=metodo_score, \n",
    "                                            janela_historico=janela_historico)\n",
    "    \n",
    "    N = len(scores)\n",
    "    p_det = np.zeros(N)\n",
    "    p_rnd = np.zeros(N)\n",
    "    \n",
    "    for n in tqdm(range(N), desc=f\"Calculando p-valores ({metodo_score})\"):\n",
    "        score_n = scores[n]\n",
    "        # Considera todos os scores até o momento atual (incluindo o atual)\n",
    "        anteriores = scores[:n+1]\n",
    "        \n",
    "        if n == 0:\n",
    "            p_det[0] = 1\n",
    "            p_rnd[0] = 1\n",
    "            continue\n",
    "        \n",
    "        # P-valor determinístico: proporção de scores maiores ou iguais\n",
    "        p_det[n] = np.mean(anteriores >= score_n)\n",
    "        \n",
    "        # P-valor randomizado: trata empates de forma aleatória\n",
    "        countG = np.sum(anteriores > score_n)\n",
    "        countE = np.sum(np.isclose(anteriores, score_n, rtol=rtol, atol=atol))\n",
    "        u = np.random.uniform() if countE > 0 else 0\n",
    "        p_rnd[n] = (countG + u * countE) / (n + 1)\n",
    "    \n",
    "    return p_det, p_rnd\n",
    "\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5d6bbee",
   "metadata": {},
   "source": [
    "### 4.  Input e preparação das tabelas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9d68195b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def carrega_prepara_dados():\n",
    "    \n",
    "    # Carregar features (valores reais)\n",
    "    features_df = pd.read_parquet('features_numerario.parquet')\n",
    "    print(f\"features: {features_df.shape}\")\n",
    "    \n",
    "    # Carregar previsões\n",
    "    previsoes_df = pd.read_csv('previsoes_numerario_pre_pos_pandemia.csv')\n",
    "    print(f\"Previsões: {previsoes_df.shape}\")\n",
    "    \n",
    "    # Padronizar nomes de colunas das previsões para combinar com features\n",
    "    previsoes_df = previsoes_df.rename(columns={\n",
    "        'DEP_CEI': 'DEPCEI',\n",
    "        'DEPOSITO': 'DEP',\n",
    "        'SAQUE': 'SAQ',\n",
    "        'SAQUE_CEI': 'SAQCEI'\n",
    "    })\n",
    "    \n",
    "    # Converter colunas de data\n",
    "    features_df['DATA'] = pd.to_datetime(features_df['DATA'])\n",
    "    previsoes_df['DATA'] = pd.to_datetime(previsoes_df['DATA'])\n",
    "    \n",
    "    # Mostrar agências disponíveis\n",
    "    agencias_features = features_df['AGENCIA'].unique()\n",
    "    agencias_previsoes = previsoes_df['AGENCIA'].unique()\n",
    "    agencias_comuns = np.intersect1d(agencias_features, agencias_previsoes)\n",
    "    \n",
    "    print(f\"\\n Resumo - agências:\")\n",
    "    print(f\"   - Agências em features: {len(agencias_features)}\")\n",
    "    print(f\"   - Agências em previsões: {len(agencias_previsoes)}\")\n",
    "    print(f\"   - Agências em comum: {len(agencias_comuns)}\")\n",
    "    \n",
    "    return features_df, previsoes_df, sorted(agencias_comuns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "10b13e31",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'features_numerario.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[26]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Carregar dados\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m features_df, previsoes_df, agencias_disponiveis = \u001b[43mcarrega_prepara_dados\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 4\u001b[39m, in \u001b[36mcarrega_prepara_dados\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcarrega_prepara_dados\u001b[39m():\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m     \u001b[38;5;66;03m# Carregar features (valores reais)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     features_df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfeatures_numerario.parquet\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mfeatures: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfeatures_df.shape\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;66;03m# Carregar previsões\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parquet.py:669\u001b[39m, in \u001b[36mread_parquet\u001b[39m\u001b[34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[39m\n\u001b[32m    666\u001b[39m     use_nullable_dtypes = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    667\u001b[39m check_dtype_backend(dtype_backend)\n\u001b[32m--> \u001b[39m\u001b[32m669\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m=\u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parquet.py:258\u001b[39m, in \u001b[36mPyArrowImpl.read\u001b[39m\u001b[34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[39m\n\u001b[32m    256\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m manager == \u001b[33m\"\u001b[39m\u001b[33marray\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m    257\u001b[39m     to_pandas_kwargs[\u001b[33m\"\u001b[39m\u001b[33msplit_blocks\u001b[39m\u001b[33m\"\u001b[39m] = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m258\u001b[39m path_or_handle, handles, filesystem = \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    259\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    260\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    261\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    262\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    263\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    264\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    265\u001b[39m     pa_table = \u001b[38;5;28mself\u001b[39m.api.parquet.read_table(\n\u001b[32m    266\u001b[39m         path_or_handle,\n\u001b[32m    267\u001b[39m         columns=columns,\n\u001b[32m   (...)\u001b[39m\u001b[32m    270\u001b[39m         **kwargs,\n\u001b[32m    271\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\parquet.py:141\u001b[39m, in \u001b[36m_get_path_or_handle\u001b[39m\u001b[34m(path, fs, storage_options, mode, is_dir)\u001b[39m\n\u001b[32m    131\u001b[39m handles = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m    133\u001b[39m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[32m    134\u001b[39m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[32m   (...)\u001b[39m\u001b[32m    139\u001b[39m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[32m    140\u001b[39m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m141\u001b[39m     handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstorage_options\u001b[49m\n\u001b[32m    143\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    144\u001b[39m     fs = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    145\u001b[39m     path_or_handle = handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\pandas\\io\\common.py:882\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    873\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(\n\u001b[32m    874\u001b[39m             handle,\n\u001b[32m    875\u001b[39m             ioargs.mode,\n\u001b[32m   (...)\u001b[39m\u001b[32m    878\u001b[39m             newline=\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    879\u001b[39m         )\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m882\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    883\u001b[39m     handles.append(handle)\n\u001b[32m    885\u001b[39m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'features_numerario.parquet'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Carregar dados\n",
    "features_df, previsoes_df, agencias_disponiveis = carrega_prepara_dados()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1f5be6",
   "metadata": {},
   "source": [
    "\n",
    "### 5. Seleção de Agência para Análise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a323808",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Agências disponíveis: {agencias_disponiveis[:20]}...\")  \n",
    "print(f\"Total de agências: {len(agencias_disponiveis)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a50c3ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escolher agência \n",
    "AGENCIA_ESCOLHIDA = agencias_disponiveis[0]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276d3b84",
   "metadata": {},
   "outputs": [],
   "source": [
    "AGENCIA_ESCOLHIDA = 20  # Substitua pelo ID agência "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348955a2",
   "metadata": {},
   "source": [
    "### 6. Merge dos Dados para a Agência Selecionada"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da3703c6",
   "metadata": {},
   "source": [
    "merge entre valores reais e previstos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cb6f540",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preparar_dados_agencia(features_df, previsoes_df, agencia):\n",
    "    \n",
    "    # Filtrar dados da agência\n",
    "    features_agencia = features_df[features_df['AGENCIA'] == agencia].copy()\n",
    "    previsoes_agencia = previsoes_df[previsoes_df['AGENCIA'] == agencia].copy()\n",
    "    \n",
    "    print(f\"   - Registros em features: {len(features_agencia)}\")\n",
    "    print(f\"   - Registros em previsões: {len(previsoes_agencia)}\")\n",
    "    \n",
    "    # Variáveis alvo\n",
    "    variaveis_alvo = ['SAQ', 'DEP', 'SAQCEI', 'DEPCEI']\n",
    "    \n",
    "    # Criar DataFrames separados para cada variável\n",
    "    dfs_merged = {}\n",
    "    \n",
    "    for var in variaveis_alvo:\n",
    "        # Selecionar colunas necessárias\n",
    "        df_real = features_agencia[['DATA', var]].copy()\n",
    "        df_real.columns = ['DATA', f'{var}_REAL'] #Adiciona label _REAL na frente\n",
    "        \n",
    "        df_pred = previsoes_agencia[['DATA', var]].copy()\n",
    "        df_pred.columns = ['DATA', f'{var}_PRED'] #Adiciona label _PRED na frente\n",
    "        \n",
    "        # Merge por DATA\n",
    "        df_merged = pd.merge(df_real, df_pred, on='DATA', how='inner')\n",
    "        \n",
    "        # Ordenar por data\n",
    "        df_merged = df_merged.sort_values('DATA').reset_index(drop=True)\n",
    "        \n",
    "        # Calcular erro (diferença real - predito)\n",
    "        df_merged['ERRO'] = df_merged[f'{var}_REAL'] - df_merged[f'{var}_PRED']\n",
    "        \n",
    "        dfs_merged[var] = df_merged\n",
    "        \n",
    "        print(f\"- {var}: {len(df_merged)} registros após merge\")\n",
    "    \n",
    "    # Verificar período de dados\n",
    "    primeira_data = min(df['DATA'].min() for df in dfs_merged.values())\n",
    "    ultima_data = max(df['DATA'].max() for df in dfs_merged.values())\n",
    "    print(f\"\\n Período de análise: {primeira_data.date()} a {ultima_data.date()}\")\n",
    "    \n",
    "    return dfs_merged\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ba25f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparar dados da agência escolhida\n",
    "dfs_agencia = preparar_dados_agencia(features_df, previsoes_df, AGENCIA_ESCOLHIDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e09dcddd",
   "metadata": {},
   "source": [
    "### 7. Análise Conformal por Target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7afbcf7d",
   "metadata": {},
   "source": [
    "Função para realizar a análise de drift em cada uma das targets separadamente"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d8477aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analisar_drift_variavel(df_variavel, nome_variavel, epsilon=0.92):\n",
    "\n",
    "    print(f\" TARGET: {nome_variavel}\")\n",
    "    \n",
    "    # Extrair valores reais e preditos\n",
    "    y_real = df_variavel[f'{nome_variavel}_REAL'].values\n",
    "    y_pred = df_variavel[f'{nome_variavel}_PRED'].values\n",
    "    \n",
    "    # Estatísticas básicas\n",
    "    erro_medio = np.mean(y_real - y_pred)\n",
    "    mae = np.mean(np.abs(y_real - y_pred))\n",
    "    rmse = np.sqrt(np.mean((y_real - y_pred)**2))\n",
    "    \n",
    "    print(f\"\\n Estatísticas do modelo:\")\n",
    "    print(f\"   - Erro médio: {erro_medio:.2f}\")\n",
    "    print(f\"   - MAE: {mae:.2f}\")\n",
    "    print(f\"   - RMSE: {rmse:.2f}\")\n",
    "    \n",
    "    # Calcular p-valores\n",
    "    p_det, p_rnd = calcular_pvalores_pred(y_real, y_pred)\n",
    "    \n",
    "    # Calcular martingales\n",
    "    mart_power_det = power_martingale(p_det, epsilon)\n",
    "    mart_power_rnd = power_martingale(p_rnd, epsilon)\n",
    "    mart_jumper_det = simple_jumper_martingale(p_det)\n",
    "    mart_jumper_rnd = simple_jumper_martingale(p_rnd)\n",
    "    \n",
    "    # Detectar pontos de mudança (threshold = 20 corresponde a α = 0.05)\n",
    "    threshold = 20\n",
    "    mudancas_power = np.where(mart_power_rnd > threshold)[0]\n",
    "    mudancas_jumper = np.where(mart_jumper_rnd > threshold)[0]\n",
    "    \n",
    "    print(f\"   - Power Martingale: {len(mudancas_power)} pontos detectados\")\n",
    "    if len(mudancas_power) > 0:\n",
    "        print(f\"     Primeira detecção: índice {mudancas_power[0]} ({df_variavel.iloc[mudancas_power[0]]['DATA'].date()})\")\n",
    "    \n",
    "    print(f\"   - Simple Jumper: {len(mudancas_jumper)} pontos detectados\")\n",
    "    if len(mudancas_jumper) > 0:\n",
    "        print(f\"     Primeira detecção: índice {mudancas_jumper[0]} ({df_variavel.iloc[mudancas_jumper[0]]['DATA'].date()})\")\n",
    "    \n",
    "    # Retornar resultados\n",
    "    return {\n",
    "        'df': df_variavel,\n",
    "        'p_valores': {'det': p_det, 'rnd': p_rnd},\n",
    "        'martingales': {\n",
    "            'power_det': mart_power_det,\n",
    "            'power_rnd': mart_power_rnd,\n",
    "            'jumper_det': mart_jumper_det,\n",
    "            'jumper_rnd': mart_jumper_rnd\n",
    "        },\n",
    "        'deteccoes': {\n",
    "            'power': mudancas_power,\n",
    "            'jumper': mudancas_jumper\n",
    "        },\n",
    "        'metricas': {\n",
    "            'erro_medio': erro_medio,\n",
    "            'mae': mae,\n",
    "            'rmse': rmse\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81670e78",
   "metadata": {},
   "source": [
    "##### aplica os diferentes métodos de score e compara resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8826927",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "def analisar_drift_variavel(df_variavel, nome_variavel, features_agencia, epsilon=0.92):\n",
    "\n",
    "    #Analisa drift para uma variável usando múltiplos scores de não-conformidade.\n",
    "    \n",
    "    #Args:\n",
    "      #  df_variavel: DataFrame com dados da variável (real, pred, erro)\n",
    "      #  nome_variavel: Nome da variável sendo analisada\n",
    "      #  features_agencia: DataFrame com features da agência (já filtrado)\n",
    "      #  epsilon: Parâmetro do power martingale\n",
    "    \n",
    "    # Definir métodos a comparar\n",
    "    metodos_scores = ['absoluto', 'relativo', 'z_score', 'mad', \n",
    "                      'dist_min', 'dist_media', 'contexto', 'multi_contexto']\n",
    "    \n",
    "    resultados_por_metodo = {}\n",
    "    \n",
    "    # Comparar cada método\n",
    "    for metodo in metodos_scores:\n",
    "        print(f\"\\n Testando método: {metodo.upper()}\")\n",
    "        \n",
    "        # Para métodos contextuais, precisamos das features\n",
    "        if metodo in ['contexto', 'multi_contexto']:\n",
    "            # Fazer merge com features de calendário\n",
    "            df_contexto = pd.merge(df_variavel, df_features_completo, \n",
    "                                 on=['AGENCIA', 'DATA'], how='left')\n",
    "            \n",
    "            # Selecionar features relevantes\n",
    "            features_contexto = ['DIA_SEMANA', 'SEMANA_QUINTO_DU', 'DIA_FERIADO', \n",
    "                               'DIA_UTIL', 'EMENDA', 'DIA_ADJACENTE_FERIADO']\n",
    "            contexto_df = df_contexto[features_contexto]\n",
    "            tipo_dia = df_contexto['DIA_SEMANA'].values\n",
    "        else:\n",
    "            contexto_df = None\n",
    "            tipo_dia = None\n",
    "        \n",
    "        # Calcular p-valores com o método específico\n",
    "        p_det, p_rnd = calcular_pvalores_pred_com_score(\n",
    "            y_real, y_pred, \n",
    "            metodo_score=metodo,\n",
    "            janela_historico=30,\n",
    "            contexto_features=contexto_df,\n",
    "            tipo_dia=tipo_dia\n",
    "        )\n",
    "        \n",
    "        # Calcular martingales\n",
    "        mart_power = power_martingale(p_rnd, epsilon)\n",
    "        mart_jumper = simple_jumper_martingale(p_rnd)\n",
    "        \n",
    "        # Detectar mudanças\n",
    "        threshold = 20\n",
    "        mudancas_power = np.where(mart_power > threshold)[0]\n",
    "        mudancas_jumper = np.where(mart_jumper > threshold)[0]\n",
    "        \n",
    "        # Armazenar resultados\n",
    "        resultados_por_metodo[metodo] = {\n",
    "            'p_valores': {'det': p_det, 'rnd': p_rnd},\n",
    "            'martingales': {\n",
    "                'power': mart_power,\n",
    "                'jumper': mart_jumper\n",
    "            },\n",
    "            'deteccoes': {\n",
    "                'power': mudancas_power,\n",
    "                'jumper': mudancas_jumper\n",
    "            },\n",
    "            'primeira_deteccao': mudancas_power[0] if len(mudancas_power) > 0 else None,\n",
    "            'max_martingale': np.max(mart_power)\n",
    "        }\n",
    "        \n",
    "        # Imprimir resumo\n",
    "        print(f\"   - Detecções (Power): {len(mudancas_power)}\")\n",
    "        if len(mudancas_power) > 0:\n",
    "            print(f\"   - Primeira detecção: índice {mudancas_power[0]} \" +\n",
    "                  f\"({df_variavel.iloc[mudancas_power[0]]['DATA'].date()})\")\n",
    "        print(f\"   - Max martingale: {np.max(mart_power):.2f}\")\n",
    "    \n",
    "    \n",
    "    return {\n",
    "        'metodos': resultados_por_metodo,\n",
    "        'df': df_variavel,\n",
    "        'estatisticas': {\n",
    "            'erro_medio': np.mean(y_real - y_pred),\n",
    "            'mae': np.mean(np.abs(y_real - y_pred)),\n",
    "            'rmse': np.sqrt(np.mean((y_real - y_pred)**2))\n",
    "        }\n",
    "    }\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724161a1",
   "metadata": {},
   "source": [
    "### 8. Executar loop para rodar todas as targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54284bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "resultados = {}\n",
    "variaveis = ['SAQ', 'DEP', 'SAQCEI', 'DEPCEI']\n",
    "\n",
    "for var in variaveis:\n",
    "    if var in dfs_agencia and len(dfs_agencia[var]) > 0:\n",
    "        resultados[var] = analisar_drift_variavel(dfs_agencia[var], var, features_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c760afe6",
   "metadata": {},
   "source": [
    "\"\"\"para executar múltiplos métodos\"\"\"\n",
    "\n",
    "elif metodo == 'contexto':\n",
    "    # G. Score Contextual por Tipo de Dia\n",
    "    # Precisa receber contexto_features e tipo_dia como parâmetros\n",
    "    for i in range(n):\n",
    "        if i < janela_historico:\n",
    "            scores[i] = np.abs(erros[i])  # Fallback simples no início\n",
    "        else:\n",
    "            # Encontrar dias similares no histórico\n",
    "            tipo_atual = tipo_dia[i]\n",
    "            mask_similar = tipo_dia[i-janela_historico:i] == tipo_atual\n",
    "            \n",
    "            if np.any(mask_similar):\n",
    "                erros_similares = erros[i-janela_historico:i][mask_similar]\n",
    "                if len(erros_similares) > 0:\n",
    "                    mad = np.median(np.abs(erros_similares - np.median(erros_similares)))\n",
    "                    scores[i] = np.abs(erros[i]) / (1.4826 * mad + epsilon)\n",
    "                else:\n",
    "                    scores[i] = np.abs(erros[i])\n",
    "            else:\n",
    "                scores[i] = np.abs(erros[i])\n",
    "\n",
    "elif metodo == 'multi_contexto':\n",
    "    # H. Score Multi-contextual (necessita scipy)\n",
    "    from scipy.spatial.distance import mahalanobis\n",
    "    from scipy.linalg import pinv\n",
    "    # ... implementação com distância de Mahalanobis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54bef5a8",
   "metadata": {},
   "source": [
    "\n",
    "### 9. Visualizações\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cc03157",
   "metadata": {},
   "source": [
    "Função gerar gráfico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e708ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_analise_completa(resultados, variavel):\n",
    "\n",
    "    if variavel not in resultados:\n",
    "        print(f\" Variável {variavel} não encontrada nos resultados!\")\n",
    "        return\n",
    "    \n",
    "    res = resultados[variavel]\n",
    "    df = res['df']\n",
    "    \n",
    "    # Criar figura com subplots\n",
    "    fig, axes = plt.subplots(4, 1, figsize=(14, 16))\n",
    "    \n",
    "    # 1. Valores Reais vs Preditos\n",
    "    ax1 = axes[0]\n",
    "    ax1.plot(df['DATA'], df[f'{variavel}_REAL'], label='Real', alpha=0.7, linewidth=1.5)\n",
    "    ax1.plot(df['DATA'], df[f'{variavel}_PRED'], label='Predito', alpha=0.7, linewidth=1.5)\n",
    "    ax1.set_title(f'{variavel} - Valores Reais vs Preditos', fontsize=14, fontweight='bold')\n",
    "    ax1.set_xlabel('Data')\n",
    "    ax1.set_ylabel('Valor')\n",
    "    ax1.legend()\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Marcar detecções\n",
    "    for idx in res['deteccoes']['power'][:5]:  # Primeiras 5 detecções\n",
    "        ax1.axvline(df.iloc[idx]['DATA'], color='red', linestyle='--', alpha=0.5)\n",
    "    \n",
    "    # 2. Erro ao longo do tempo\n",
    "    ax2 = axes[1]\n",
    "    ax2.plot(df['DATA'], df['ERRO'], color='orange', alpha=0.7)\n",
    "    ax2.axhline(y=0, color='black', linestyle='-', alpha=0.3)\n",
    "    ax2.fill_between(df['DATA'], df['ERRO'], 0, alpha=0.3, color='orange')\n",
    "    ax2.set_title('Erro de Predição (Real - Predito)', fontsize=14, fontweight='bold')\n",
    "    ax2.set_xlabel('Data')\n",
    "    ax2.set_ylabel('Erro')\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. P-valores ao longo do tempo\n",
    "    ax3 = axes[2]\n",
    "    ax3.plot(df['DATA'], res['p_valores']['det'], label='P-valor Det.', alpha=0.7)\n",
    "    ax3.plot(df['DATA'], res['p_valores']['rnd'], label='P-valor Rnd.', alpha=0.7)\n",
    "    ax3.axhline(y=0.05, color='red', linestyle='--', alpha=0.5, label='α=0.05')\n",
    "    ax3.set_title('P-valores Conformais', fontsize=14, fontweight='bold')\n",
    "    ax3.set_xlabel('Data')\n",
    "    ax3.set_ylabel('P-valor')\n",
    "    ax3.set_ylim([0, 1])\n",
    "    ax3.legend()\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Martingales (escala log)\n",
    "    ax4 = axes[3]\n",
    "    ax4.plot(df['DATA'], res['martingales']['power_rnd'], \n",
    "             label='Power Martingale', color='blue', linewidth=2)\n",
    "    ax4.plot(df['DATA'], res['martingales']['jumper_rnd'], \n",
    "             label='Simple Jumper', color='green', linewidth=2)\n",
    "    ax4.axhline(y=20, color='red', linestyle='--', alpha=0.5, label='Threshold (α=0.05)')\n",
    "    ax4.set_yscale('log')\n",
    "    ax4.set_title('Martingales para Detecção de Drift', fontsize=14, fontweight='bold')\n",
    "    ax4.set_xlabel('Data')\n",
    "    ax4.set_ylabel('Martingale (log scale)')\n",
    "    ax4.legend()\n",
    "    ax4.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Marcar pontos de mudança detectados\n",
    "    for idx in res['deteccoes']['power'][:5]:\n",
    "        ax4.axvline(df.iloc[idx]['DATA'], color='red', linestyle=':', alpha=0.7)\n",
    "        ax4.text(df.iloc[idx]['DATA'], ax4.get_ylim()[1]*0.8, 'Drift!', \n",
    "                rotation=90, verticalalignment='bottom', color='red')\n",
    "    \n",
    "    plt.suptitle(f'Análise de Drift - Agência {AGENCIA_ESCOLHIDA}', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e671039",
   "metadata": {},
   "source": [
    "gerar gráfico para cada target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c13411d",
   "metadata": {},
   "outputs": [],
   "source": [
    "for var in variaveis:\n",
    "    if var in resultados:\n",
    "        plotar_analise_completa(resultados, var)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54a4dd4a",
   "metadata": {},
   "source": [
    "para múltiplos métodos: \n",
    "\n",
    "def plotar_comparacao_metodos(resultados_variavel):\n",
    "    \"\"\"\n",
    "    Compara os diferentes métodos de score para uma variável.\n",
    "    \"\"\"\n",
    "    metodos = resultados_variavel['metodos']\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    \n",
    "    for metodo, res in metodos.items():\n",
    "        ax.plot(res['martingales']['power'], label=f'{metodo}', alpha=0.7)\n",
    "    \n",
    "    ax.set_yscale('log')\n",
    "    ax.axhline(y=20, color='red', linestyle='--', alpha=0.5)\n",
    "    ax.legend()\n",
    "    ax.set_title('Comparação de Métodos de Score')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c041e55",
   "metadata": {},
   "source": [
    "\n",
    "### 10. Análise Comparativa entre Variáveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382870fd",
   "metadata": {},
   "source": [
    "visualização comparando os targets "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ba5f499",
   "metadata": {},
   "source": [
    "1. **P-valores baixos** indicam observações não-conformes (possível drift)\n",
    "2. **Martingales crescentes** sinalizam mudança sistemática no comportamento\n",
    "3. **Threshold = 20** corresponde a nível de significância α = 0.05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69962669",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotar_comparacao_variaveis(resultados):\n",
    "\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "    axes = axes.flatten()\n",
    "    \n",
    "    for idx, (var, res) in enumerate(resultados.items()):\n",
    "        if idx >= 4:\n",
    "            break\n",
    "            \n",
    "        ax = axes[idx]\n",
    "        df = res['df']\n",
    "        \n",
    "        # Plotar martingale Power (mais sensível)\n",
    "        ax.plot(df['DATA'], res['martingales']['power_rnd'], \n",
    "                linewidth=2, label='Power Martingale')\n",
    "        \n",
    "        # Linha de threshold\n",
    "        ax.axhline(y=20, color='red', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # Marcar detecções\n",
    "        for det_idx in res['deteccoes']['power'][:3]:\n",
    "            ax.axvline(df.iloc[det_idx]['DATA'], color='red', linestyle=':', alpha=0.7)\n",
    "        \n",
    "        ax.set_yscale('log')\n",
    "        ax.set_title(f'{var} - Power Martingale', fontweight='bold')\n",
    "        ax.set_xlabel('Data')\n",
    "        ax.set_ylabel('Martingale (log)')\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Adicionar texto com estatísticas\n",
    "        texto_stats = f\"MAE: {res['metricas']['mae']:.2f}\\n\"\n",
    "        texto_stats += f\"Detecções: {len(res['deteccoes']['power'])}\"\n",
    "        ax.text(0.02, 0.98, texto_stats, transform=ax.transAxes, \n",
    "                verticalalignment='top', bbox=dict(boxstyle='round', \n",
    "                facecolor='wheat', alpha=0.5))\n",
    "    \n",
    "    plt.suptitle(f'Comparação de Drift entre Variáveis - Agência {AGENCIA_ESCOLHIDA}', \n",
    "                 fontsize=16, fontweight='bold')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40180c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plotar_comparacao_variaveis(resultados)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc6896e",
   "metadata": {},
   "source": [
    "para drif de dias consecutivos:\n",
    "\n",
    "def detectar_drift_com_filtro(martingale, threshold=20, min_consecutivos=3):\n",
    "    \"\"\"\n",
    "    Detecta drift exigindo múltiplas detecções consecutivas.\n",
    "    \"\"\"\n",
    "    deteccoes_brutas = martingale > threshold\n",
    "    deteccoes_filtradas = []\n",
    "    \n",
    "    contador = 0\n",
    "    for i, detectado in enumerate(deteccoes_brutas):\n",
    "        if detectado:\n",
    "            contador += 1\n",
    "            if contador >= min_consecutivos:\n",
    "                # Adiciona o primeiro índice da sequência\n",
    "                deteccoes_filtradas.append(i - min_consecutivos + 1)\n",
    "                contador = 0  # Reset para evitar múltiplas detecções\n",
    "        else:\n",
    "            contador = 0\n",
    "    \n",
    "    return np.array(deteccoes_filtradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6339be0",
   "metadata": {},
   "source": [
    "\n",
    "### 11. Resumo da Análise\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6bef40",
   "metadata": {},
   "outputs": [],
   "source": [
    "def gerar_resumo_analise(resultados):\n",
    "\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(f\" RESUMO DA ANÁLISE DE DRIFT - AGÊNCIA {AGENCIA_ESCOLHIDA}\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Criar DataFrame com resumo\n",
    "    resumo_data = []\n",
    "    \n",
    "    for var, res in resultados.items():\n",
    "        df = res['df']\n",
    "        primeira_data = df['DATA'].min()\n",
    "        ultima_data = df['DATA'].max()\n",
    "        \n",
    "        # Detecções Power Martingale\n",
    "        det_power = res['deteccoes']['power']\n",
    "        primeira_det_power = df.iloc[det_power[0]]['DATA'] if len(det_power) > 0 else None\n",
    "        \n",
    "        # Detecções Simple Jumper\n",
    "        det_jumper = res['deteccoes']['jumper']\n",
    "        primeira_det_jumper = df.iloc[det_jumper[0]]['DATA'] if len(det_jumper) > 0 else None\n",
    "        \n",
    "        resumo_data.append({\n",
    "            'Variável': var,\n",
    "            'Período': f\"{primeira_data.date()} a {ultima_data.date()}\",\n",
    "            'Registros': len(df),\n",
    "            'MAE': f\"{res['metricas']['mae']:.2f}\",\n",
    "            'RMSE': f\"{res['metricas']['rmse']:.2f}\",\n",
    "            'Detecções Power': len(det_power),\n",
    "            '1ª Det. Power': primeira_det_power.date() if primeira_det_power else 'Nenhuma',\n",
    "            'Detecções Jumper': len(det_jumper),\n",
    "            '1ª Det. Jumper': primeira_det_jumper.date() if primeira_det_jumper else 'Nenhuma'\n",
    "        })\n",
    "    \n",
    "    df_resumo = pd.DataFrame(resumo_data)\n",
    "    \n",
    "    # Exibir tabela\n",
    "    print(\"\\n Tabela Resumo:\")\n",
    "    print(df_resumo.to_string(index=False))\n",
    "    \n",
    "    # Análise de período pandemia (se aplicável)\n",
    "    print(\"\\n Análise de Período Especial (Pandemia):\")\n",
    "    data_inicio_pandemia = pd.to_datetime('2020-03-01')\n",
    "    \n",
    "    for var, res in resultados.items():\n",
    "        df = res['df']\n",
    "        \n",
    "        # Verificar se há dados no período da pandemia\n",
    "        mask_pandemia = df['DATA'] >= data_inicio_pandemia\n",
    "        if mask_pandemia.any():\n",
    "            idx_pandemia = df[mask_pandemia].index[0]\n",
    "            \n",
    "            # Verificar detecções próximas ao início da pandemia\n",
    "            det_power = res['deteccoes']['power']\n",
    "            det_proximas = det_power[(det_power >= idx_pandemia - 30) & \n",
    "                                   (det_power <= idx_pandemia + 90)]\n",
    "            \n",
    "            if len(det_proximas) > 0:\n",
    "                primeira_det = df.iloc[det_proximas[0]]['DATA']\n",
    "                dias_apos_pandemia = (primeira_det - data_inicio_pandemia).days\n",
    "                print(f\"\\n   {var}: Drift detectado {dias_apos_pandemia} dias após início da pandemia\")\n",
    "                print(f\"         Data da detecção: {primeira_det.date()}\")\n",
    "            else:\n",
    "                print(f\"\\n   {var}: Nenhum drift detectado no período da pandemia\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    \n",
    "    return df_resumo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84733694",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "resumo_final = gerar_resumo_analise(resultados)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0efab985",
   "metadata": {},
   "source": [
    "### 12. Exportar Resultados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f7685ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def exportar_resultados(resultados, agencia):\n",
    "\n",
    "    import os\n",
    "    \n",
    "    # Criar diretório para resultados\n",
    "    dir_resultados = f'resultados_drift_agencia_{agencia}'\n",
    "    if not os.path.exists(dir_resultados):\n",
    "        os.makedirs(dir_resultados)\n",
    "    \n",
    "    for var, res in resultados.items():\n",
    "        # Exportar DataFrame com análise\n",
    "        df_export = res['df'].copy()\n",
    "        \n",
    "        # Adicionar colunas de p-valores e martingales\n",
    "        df_export['p_valor_det'] = res['p_valores']['det']\n",
    "        df_export['p_valor_rnd'] = res['p_valores']['rnd']\n",
    "        df_export['martingale_power'] = res['martingales']['power_rnd']\n",
    "        df_export['martingale_jumper'] = res['martingales']['jumper_rnd']\n",
    "        \n",
    "        # Marcar detecções\n",
    "        df_export['drift_detectado_power'] = False\n",
    "        df_export.loc[res['deteccoes']['power'], 'drift_detectado_power'] = True\n",
    "        \n",
    "        df_export['drift_detectado_jumper'] = False\n",
    "        df_export.loc[res['deteccoes']['jumper'], 'drift_detectado_jumper'] = True\n",
    "        \n",
    "        # Salvar arquivo\n",
    "        filename = f'{dir_resultados}/analise_drift_{var}_agencia_{agencia}.csv'\n",
    "        df_export.to_csv(filename, index=False)\n",
    "        print(f\"Resultados de {var} salvos em: {filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
