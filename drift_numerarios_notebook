#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
Framework AutoMLOps - Detecção de Drift para Numerários
Versão simplificada com features reais do projeto
"""

import pandas as pd
import numpy as np
from datetime import datetime
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
import warnings
warnings.filterwarnings('ignore')

# =============================================================================
# 1. FUNÇÕES DE CRIAÇÃO DE FEATURES (EXATAMENTE COMO NO NUMERÁRIOS)
# =============================================================================

def criarVariaveis(prep_dados):
    """
    Cria todas as features de calendário usadas no modelo Numerários
    """
    print("Criando features de calendário...")
    
    # 1-8: Gera as variáveis mais básicas do calendário
    prep_dados['DIA_SEMANA'] = prep_dados['DATA'].apply(lambda x: int(x.weekday())+2 if int(x.weekday())+2!=8 else 1)
    prep_dados['MES'] = prep_dados['DATA'].apply(lambda x: x.month)
    prep_dados['DIA_MES'] = prep_dados['DATA'].apply(lambda x: x.day)
    prep_dados['SEMANA_MES'] = prep_dados['DATA'].apply(lambda x: math.ceil((x.day)/7))
    prep_dados['DIA_FERIADO'] = prep_dados['FERIADO'].apply(lambda x: 0 if np.isnan(x) else 1)
    prep_dados['DIA_UTIL'] = 0
    prep_dados.loc[(prep_dados['DIA_SEMANA']>=2)&(prep_dados['DIA_SEMANA']<=6)&(prep_dados['DIA_FERIADO']==0), 'DIA_UTIL'] = 1
    prep_dados.loc[(prep_dados['DIA_SEMANA']>=2)&(prep_dados['DIA_SEMANA']<=6)&(prep_dados['DIA_FERIADO']==1), 'DIA_FERIADO_UTIL'] = 1
    
    # 9: quantidade de dias fechado depois
    # ordena as datas decrescentes e faz uma contagem enquanto for dia nao util
    prep_dados['switch'] = (prep_dados['DIA_UTIL'].shift(1) != prep_dados['DIA_UTIL']).astype(int)
    prep_dados['DIA_UTIL_GROUPS'] = prep_dados.groupby('AGENCIA')['switch'].cumsum()
    
    prep_dados['QTD_DIAS_FECHADO_DEPOIS_LEG'] = prep_dados.sort_values(['DATA'], ascending=False).groupby(['AGENCIA', 'DIA_UTIL_GROUPS']).cumcount() + 1
    prep_dados = prep_dados.drop(columns=['switch', 'DIA_UTIL_GROUPS'])
    
    # desloca a serie para colocar na linha correta a quantidade de dias fechados depois
    prep_dados['QTD_DIAS_FECHADO_ANTES'] = prep_dados.groupby(['AGENCIA'])['QTD_DIAS_FECHADO_DEPOIS_LEG'].shift(-1).fillna(0)
    prep_dados['QTD_DIAS_FECHADO_DEPOIS'] = prep_dados['QTD_DIAS_FECHADO_ANTES'].astype(int)
    
    # zera a serie para os outros dias
    prep_dados.loc[(prep_dados.DIA_UTIL != 1) | (prep_dados.QTD_DIAS_FECHADO_DEPOIS_LEG != 1), 'QTD_DIAS_FECHADO_DEPOIS'] = 0
    
    # 10: quantidade de dias fechado antes
    # ordena as datas crescentes e faz uma contagem enquanto for dia nao util
    prep_dados['switch'] = (prep_dados['DIA_UTIL'].shift(1) != prep_dados['DIA_UTIL']).astype(int)
    prep_dados['DIA_UTIL_GROUPS'] = prep_dados.groupby('AGENCIA')['switch'].cumsum()
    
    prep_dados['QTD_DIAS_FECHADO_ANTES_LEG'] = prep_dados.sort_values(['DATA'], ascending=True).groupby(['AGENCIA', 'DIA_UTIL_GROUPS']).cumcount() + 1
    prep_dados = prep_dados.drop(columns=['switch', 'DIA_UTIL_GROUPS'])
    
    # desloca a serie para colocar na linha correta a quantidade de dias fechados depois
    prep_dados['QTD_DIAS_FECHADO_ANTES']=prep_dados.groupby(['AGENCIA'])['QTD_DIAS_FECHADO_ANTES_LEG'].shift(1).fillna(0)
    prep_dados['QTD_DIAS_FECHADO_ANTES'] = prep_dados['QTD_DIAS_FECHADO_ANTES'].astype(int)
    
    # zera a serie para os outros dias
    prep_dados.loc[(prep_dados.DIA_UTIL != 1)| (prep_dados.QTD_DIAS_FECHADO_ANTES_LEG != 1), 'QTD_DIAS_FECHADO_ANTES'] = 0
    
    # apaga as series auxiliares criadas
    prep_dados.drop(columns = ["QTD_DIAS_FECHADO_ANTES_LEG", "QTD_DIAS_FECHADO_DEPOIS_LEG"], inplace=True)
    
    # 11 - 12: copia as series para representacao numerica da variavel
    prep_dados['QTD_DIAS_FECHADO_DEPOIS_NUM'] = prep_dados['QTD_DIAS_FECHADO_DEPOIS']
    prep_dados['QTD_DIAS_FECHADO_ANTES_NUM'] = prep_dados['QTD_DIAS_FECHADO_ANTES']
    
    # obs: para essas series as datas precisam comecar e
    # terminar no primeiro e no ultimo dia do mes respectivamente
    
    # 13: sequencia dia util positiva
    prep_dados['SEQ_DIA_UTIL'] = prep_dados.groupby(['AGENCIA','ANO','MES'])['DIA_UTIL'].cumsum()
    # zera a serie para dias nao uteis
    prep_dados.loc[(prep_dados.DIA_UTIL!=1), 'SEQ_DIA_UTIL'] = 0
    
    # 14: sequencia dia util negativa
    prep_dados['SEQ_DIA_UTIL_NEG'] = prep_dados.sort_values(['DATA'], ascending=False).groupby(['AGENCIA','ANO','MES'])['DIA_UTIL'].cumsum()
    # zera a serie para dias nao uteis
    prep_dados.loc[(prep_dados.DIA_UTIL!=1), 'SEQ_DIA_UTIL_NEG'] = 0
    
    # 15 - 16: variaveis de quantidade de dias uteis nos proximos (e anteriores) 7 dias
    prep_dados['shift_1'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(-1)
    prep_dados['shift_2'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(-2)
    prep_dados['shift_3'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(-3)
    prep_dados['shift_4'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(-4)
    prep_dados['shift_5'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(-5)
    prep_dados['shift_6'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(-6)
    prep_dados['NUM_DIAS_UTEIS_MAIS_7_DIAS'] = prep_dados['shift_1'] + prep_dados['shift_2'] + prep_dados['shift_3'] + prep_dados['shift_4'] + prep_dados['shift_5'] + prep_dados['shift_6']
    prep_dados.drop(columns=['shift_1', 'shift_2', 'shift_3', 'shift_4', 'shift_5', 'shift_6'], inplace=True)
    
    prep_dados['shift_1'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(1)
    prep_dados['shift_2'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(2)
    prep_dados['shift_3'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(3)
    prep_dados['shift_4'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(4)
    prep_dados['shift_5'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(5)
    prep_dados['shift_6'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(6)
    prep_dados['NUM_DIAS_UTEIS_MENOS_7_DIAS'] = prep_dados['shift_1'] + prep_dados['shift_2'] + prep_dados['shift_3'] + prep_dados['shift_4'] + prep_dados['shift_5'] + prep_dados['shift_6']
    prep_dados.drop(columns=['shift_1', 'shift_2', 'shift_3', 'shift_4', 'shift_5', 'shift_6'], inplace=True)
    
    prep_dados['NUM_DIAS_UTEIS_MAIS_7_DIAS'].fillna(0, inplace=True)
    prep_dados['NUM_DIAS_UTEIS_MENOS_7_DIAS'].fillna(0, inplace=True)
    prep_dados['NUM_DIAS_UTEIS_MAIS_7_DIAS'] = prep_dados.drop(columns=['NUM_DIAS_UTEIS_MAIS_7_DIAS']).astype(int)
    prep_dados['NUM_DIAS_UTEIS_MENOS_7_DIAS'] = prep_dados['NUM_DIAS_UTEIS_MENOS_7_DIAS'].astype(int)
    
    # cria variaveis auxiliares
    prep_dados['DIA_UTIL_LAG'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(1)
    prep_dados['DIA_UTIL_LEAD'] = prep_dados.groupby(['AGENCIA'])['DIA_UTIL'].shift(-1)
    
    # 17: variavel de emenda: dia entre dias entre feriados e fds
    prep_dados['EMENDA'] = 0
    prep_dados.loc[((prep_dados.DIA_UTIL_LEAD == 0) & (prep_dados.DIA_UTIL_LAG == 0) & (prep_dados.DIA_UTIL == 1)), 'EMENDA'] = 1
    
    # 18: dia adjacente feriado: que nao seja emenda
    prep_dados['DIA_ADJACENTE_FERIADO'] = 0
    prep_dados.loc[(((prep_dados.DIA_UTIL_LEAD == 0) | (prep_dados.DIA_UTIL_LAG == 0)) & (prep_dados.DIA_UTIL == 1) & (prep_dados.DIA_SEMANA.isin([3,4,5]))), 'DIA_ADJACENTE_FERIADO'] = 1
    
    # cria variavel auxiliar de emenda
    prep_dados['EMENDA_LAG'] = prep_dados.groupby(['AGENCIA'])['EMENDA'].shift(1)
    prep_dados['EMENDA_LEAD'] = prep_dados.groupby(['AGENCIA'])['EMENDA'].shift(-1)
    
    # 19: finais de semana de feriado
    # cria a variavel de fds de feriado
    prep_dados['FDS_DE_FERIADO'] = 0
    prep_dados.loc[(((prep_dados.DIA_SEMANA==1)&((prep_dados.EMENDA_LEAD == 1) | (prep_dados.DIA_UTIL_LEAD == 0))) | 
                    ((prep_dados.DIA_SEMANA==7)&((prep_dados.EMENDA_LAG == 1) | (prep_dados.DIA_UTIL_LAG == 0)))), 'FDS_DE_FERIADO'] = 1
    
    # ajusta a variavel para aparecer tanto no sabado quanto no domingo
    prep_dados.loc[((prep_dados.DIA_SEMANA==1) | (prep_dados.DIA_SEMANA==7)) & ((prep_dados.FDS_DE_FERIADO == 1) | (prep_dados.FDS_DE_FERIADO_LAG == 1) | (prep_dados.FDS_DE_FERIADO_LEAD == 1)), 'FDS_DE_FERIADO'] = 1
    
    # retira as variaveis auxiliares
    prep_dados.drop(columns = ['DIA_UTIL_LEAD', 'DIA_UTIL_LAG', 'EMENDA_LEAD', 'EMENDA_LAG', 'FDS_DE_FERIADO_LAG', 'FDS_DE_FERIADO_LEAD'], inplace=True)
    
    # 20 - 22: semana quinto dia util e semana anterior e apos
    # coluna aux para segunda feira e faz a soma acumulada para numerar semanas
    prep_dados['SEGUNDA_AUX'] = 0
    prep_dados.loc[(prep_dados.DIA_SEMANA == 2), 'SEGUNDA_AUX'] = 1
    prep_dados['NUM_SEMANA'] = prep_dados.groupby(['AGENCIA'])['SEGUNDA_AUX'].cumsum()
    
    # cria base auxiliar com as semanas com o quinto dia util
    semana_5du = prep_dados[prep_dados['SEQ_DIA_UTIL']==5][['AGENCIA','NUM_SEMANA']].drop_duplicates()
    semana_5du['SEMANA_QUINTO_DU'] = 1
    semana_5du['NUM_SEMANA_ANTERIOR'] = semana_5du['NUM_SEMANA'] - 1
    semana_5du['NUM_SEMANA_APOS'] = semana_5du['NUM_SEMANA'] + 1
    
    # faz o join
    prep_dados = pd.merge(prep_dados, semana_5du[['AGENCIA', 'NUM_SEMANA', 'SEMANA_QUINTO_DU']], on=['AGENCIA','NUM_SEMANA'], how='left')
    
    prep_dados = pd.merge(prep_dados, semana_5du[['AGENCIA', 'NUM_SEMANA_ANTERIOR', 'SEMANA_ANTERIOR_QUINTO_DU']], left_on=['AGENCIA','NUM_SEMANA'], right_on=['AGENCIA','NUM_SEMANA_ANTERIOR'], how='left')
    prep_dados.drop(columns=['CO_MUNICIPIO','NUM_SEMANA_ANTERIOR'], inplace=True)
    
    prep_dados = pd.merge(prep_dados, semana_5du[['AGENCIA', 'NUM_SEMANA_APOS', 'SEMANA_APOS_QUINTO_DU']], left_on=['AGENCIA','NUM_SEMANA'], right_on=['AGENCIA','NUM_SEMANA_APOS'], how='left')
    prep_dados.drop(columns=['NUM_SEMANA_APOS'], inplace=True)
    
    # transforma NA em zero
    prep_dados['SEMANA_QUINTO_DU'].fillna(0, inplace=True)
    prep_dados['SEMANA_ANTERIOR_QUINTO_DU'].fillna(0, inplace=True)
    prep_dados['SEMANA_APOS_QUINTO_DU'].fillna(0, inplace=True)
    
    # tira as colunas auxiliares
    prep_dados.drop(columns = ['SEGUNDA_AUX', 'NUM_SEMANA'], inplace=True)
    
    # 23: dia mes ajustado
    # dia util anterior recebe os valores do dia do mes dos dias nao uteis seguintes
    # util para casos onde o pagamento é feito pelo dia do mes e é adiantado
    # caso o dia do mes do pagamento caia em um dia nao util
    
    # dia mes ajustado - transfere para o dia
    # sequencia dia util auxiliar
    prep_dados['SEQ_DIA_UTIL_AUX'] = prep_dados.sort_values(['AGENCIA','DATA']).groupby(['AGENCIA','ANO','MES'])['DIA_UTIL'].cumsum()
    
    dia_mes_aux = prep_dados[['AGENCIA','ANO','MES','SEQ_DIA_UTIL_AUX','DIA_MES','DIA_SEMANA']].rename({'DIA_SEMANA':'DIA_MES_AJUSTADO'}, axis=1).pivot_table(index=['AGENCIA','ANO','MES','SEQ_DIA_UTIL_AUX'], columns='DIA_MES', values='DIA_MES_AJUSTADO')
    dia_mes_aux.columns = [str(dia_mes_aux.columns.droplevel(0)[i]) + '_' + str(dia_mes_aux.columns.droplevel(0)[i]) for i in range(0,32)]
    dia_mes_aux.rename({'AGENCIA_':'AGENCIA', 'ANO_':'ANO', 'MES_':'MES', 'SEQ_DIA_UTIL_AUX_':'SEQ_DIA_UTIL_AUX'}, axis=1, inplace=True)
    
    for i in range(1,32):
        dia_mes_aux.loc[~np.isnan(dia_mes_aux['DIA_MES_AJUSTADO_'+str(i)]), 'DIA_MES_AJUSTADO_'+str(i)] = i
    
    prep_dados = pd.merge(prep_dados, dia_mes_aux, on=['AGENCIA','ANO','MES','SEQ_DIA_UTIL_AUX'], how='left')
    
    cols_dia_mes = ['DIA_MES_AJUSTADO_'+str(x) for x in range(1,32)]
    
    # transforma NA em zero para outros valores em 1
    for col in cols_dia_mes:
        prep_dados.loc[~np.isnan(prep_dados[col]), col] = 1
        prep_dados.loc[np.isnan(prep_dados[col]), col] = 0
    
    # zera a serie para dias nao uteis
    prep_dados.loc[prep_dados['DIA_UTIL']!=1, cols_dia_mes] = 0
    
    return prep_dados

# =============================================================================
# 2. CLASSE SIMPLIFICADA DO DETECTOR CONFORMAL
# =============================================================================

class DetectorConformalSimples:
    """
    Detector conformal simplificado para Numerários
    """
    
    def __init__(self, alpha=0.05, epsilon=0.92):
        self.alpha = alpha
        self.epsilon = epsilon
        self.threshold = 1 / alpha
        self.janela_calibracao = 90  # 3 meses
        
    def calcular_score(self, valor_atual, historico, tipo_contexto=None):
        """
        Calcula score de não-conformidade
        """
        if len(historico) < 5:
            return 0
            
        # Estatísticas robustas
        mediana = np.median(historico)
        mad = np.median(np.abs(historico - mediana))
        
        if mad > 0:
            score = np.abs(valor_atual - mediana) / mad
        else:
            std = np.std(historico)
            score = np.abs(valor_atual - mediana) / (std + 1e-8)
            
        return score
    
    def calcular_pvalor(self, score_atual, scores_historicos):
        """
        Calcula p-valor conformal
        """
        if len(scores_historicos) == 0:
            return 1.0
            
        n = len(scores_historicos)
        n_maiores = np.sum(scores_historicos >= score_atual)
        
        # Tratar empates
        n_empates = np.sum(np.abs(scores_historicos - score_atual) < 1e-8)
        if n_empates > 0:
            u = np.random.uniform()
            p_valor = (n_maiores - n_empates + u * n_empates + 1) / (n + 1)
        else:
            p_valor = (n_maiores + 1) / (n + 1)
            
        return max(p_valor, 1e-10)
    
    def power_martingale(self, p_valores):
        """
        Calcula Power Martingale
        """
        if len(p_valores) == 0:
            return np.array([])
            
        martingale = np.zeros(len(p_valores))
        martingale[0] = self.epsilon * p_valores[0] ** (self.epsilon - 1)
        
        for t in range(1, len(p_valores)):
            incremento = self.epsilon * p_valores[t] ** (self.epsilon - 1)
            martingale[t] = martingale[t-1] * incremento
            
            # Evitar overflow/underflow
            if martingale[t] > 1e10:
                martingale[t] = 1e10
            elif martingale[t] < 1e-10:
                martingale[t] = 1e-10
                
        return martingale
    
    def detectar_drift(self, df, variavel, contexto_col=None):
        """
        Detecta drift em uma variável
        """
        n = len(df)
        scores = np.zeros(n)
        p_valores = np.zeros(n)
        
        # Calcular scores
        for i in range(n):
            if i < self.janela_calibracao:
                scores[i] = 0
                p_valores[i] = 1.0
            else:
                # Janela histórica
                inicio = max(0, i - self.janela_calibracao)
                
                # Se tiver contexto, filtrar por tipo similar
                if contexto_col and contexto_col in df.columns:
                    contexto_atual = df.iloc[i][contexto_col]
                    mask_contexto = df.iloc[inicio:i][contexto_col] == contexto_atual
                    
                    if mask_contexto.sum() > 10:
                        historico = df.iloc[inicio:i][mask_contexto][variavel].values
                    else:
                        historico = df.iloc[inicio:i][variavel].values
                else:
                    historico = df.iloc[inicio:i][variavel].values
                
                # Score
                valor_atual = df.iloc[i][variavel]
                scores[i] = self.calcular_score(valor_atual, historico)
                
                # P-valor
                scores_hist = scores[inicio:i]
                p_valores[i] = self.calcular_pvalor(scores[i], scores_hist)
        
        # Calcular martingale
        martingale = np.ones(n)
        if n > self.janela_calibracao:
            mart_calc = self.power_martingale(p_valores[self.janela_calibracao:])
            martingale[self.janela_calibracao:] = mart_calc
        
        # Detectar drift
        deteccoes = martingale > self.threshold
        
        return {
            'scores': scores,
            'p_valores': p_valores,
            'martingale': martingale,
            'deteccoes': deteccoes
        }

# =============================================================================
# 3. ANÁLISE PRINCIPAL
# =============================================================================

def analisar_drift_numerarios(filepath, agencia_id=None):
    """
    Função principal de análise
    """
    print("=== ANÁLISE DE DRIFT - NUMERÁRIOS ===\n")
    
    # 1. Carregar dados
    print("1. Carregando dados...")
    df = pd.read_csv(filepath)
    
    # Converter datas
    df['DATA'] = pd.to_datetime(df['DATA'])
    df['DATA_REFERENCIA'] = pd.to_datetime(df['DATA_REFERENCIA'], errors='coerce')
    df['DATA_PREVISAO'] = pd.to_datetime(df['DATA_PREVISAO'])
    
    # Adicionar colunas necessárias se não existirem
    if 'ANO' not in df.columns:
        df['ANO'] = df['DATA'].dt.year
    
    # Simular coluna FERIADO se não existir
    if 'FERIADO' not in df.columns:
        # Lista de feriados exemplo
        feriados = pd.to_datetime([
            '2019-01-01', '2019-04-19', '2019-04-21', '2019-05-01',
            '2020-01-01', '2020-02-24', '2020-02-25', '2020-04-10',
            '2020-04-21', '2020-05-01', '2020-06-11', '2020-09-07',
            '2020-10-12', '2020-11-02', '2020-11-15', '2020-12-25',
            '2021-01-01', '2021-02-15', '2021-02-16'
        ])
        df['FERIADO'] = df['DATA'].apply(lambda x: 1 if x in feriados else np.nan)
    
    # Selecionar agência
    if agencia_id is None:
        agencia_id = df['AGENCIA'].iloc[0]
    
    df_agencia = df[df['AGENCIA'] == agencia_id].copy()
    df_agencia = df_agencia.sort_values('DATA').reset_index(drop=True)
    
    print(f"   Agência: {agencia_id}")
    print(f"   Período: {df_agencia['DATA'].min()} a {df_agencia['DATA'].max()}")
    print(f"   Total de observações: {len(df_agencia)}")
    
    # 2. Criar features
    print("\n2. Criando features de calendário...")
    
    # Importar math para a função
    import math
    df_agencia = criarVariaveis(df_agencia)
    
    # 3. Criar detector
    print("\n3. Configurando detector conformal...")
    detector = DetectorConformalSimples(alpha=0.05, epsilon=0.92)
    
    # 4. Analisar cada variável
    variaveis = ['SAQUE', 'SAQUE_CEI', 'DEPOSITO', 'DEP_CEI']
    resultados = {}
    
    print("\n4. Detectando drift...")
    for var in variaveis:
        print(f"   - Analisando {var}...")
        resultados[var] = detector.detectar_drift(df_agencia, var, contexto_col='SEMANA_QUINTO_DU')
    
    # 5. Visualizar resultados
    print("\n5. Gerando visualizações...")
    visualizar_resultados(df_agencia, resultados, variaveis)
    
    # 6. Relatório
    gerar_relatorio(df_agencia, resultados, variaveis)
    
    return df_agencia, resultados

def visualizar_resultados(df, resultados, variaveis):
    """
    Cria visualizações dos resultados
    """
    # Data da pandemia
    data_pandemia = pd.to_datetime('2020-03-01')
    
    # Criar figura com subplots
    fig, axes = plt.subplots(len(variaveis), 2, figsize=(18, 4*len(variaveis)))
    
    for i, var in enumerate(variaveis):
        res = resultados[var]
        
        # Martingale
        ax1 = axes[i, 0]
        ax1.semilogy(df['DATA'], res['martingale'], 'b-', linewidth=2)
        ax1.axhline(20, color='red', linestyle='--', label='Threshold')
        ax1.axvline(data_pandemia, color='black', linestyle='--', alpha=0.5, label='Pandemia')
        
        # Marcar detecções
        if any(res['deteccoes']):
            idx_det = np.where(res['deteccoes'])[0]
            ax1.scatter(df['DATA'].iloc[idx_det], res['martingale'][idx_det],
                       color='red', s=100, marker='v', label='Drift')
        
        ax1.set_title(f'Martingale - {var}')
        ax1.set_xlabel('Data')
        ax1.set_ylabel('Martingale (log)')
        ax1.legend()
        ax1.grid(True, alpha=0.3)
        
        # P-valores
        ax2 = axes[i, 1]
        ax2.plot(df['DATA'], res['p_valores'], 'g-', alpha=0.7)
        ax2.axhline(0.05, color='red', linestyle=':', label='α=0.05')
        ax2.axvline(data_pandemia, color='black', linestyle='--', alpha=0.5)
        ax2.set_title(f'P-valores - {var}')
        ax2.set_xlabel('Data')
        ax2.set_ylabel('P-valor')
        ax2.set_ylim(0, 1.1)
        ax2.legend()
        ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('drift_numerarios_resultados.png', dpi=300, bbox_inches='tight')
    plt.show()

def gerar_relatorio(df, resultados, variaveis):
    """
    Gera relatório dos resultados
    """
    data_pandemia = pd.to_datetime('2020-03-01')
    idx_pandemia = (df['DATA'] >= data_pandemia).argmax()
    
    print("\n=== RELATÓRIO DE DETECÇÃO DE DRIFT ===\n")
    
    for var in variaveis:
        res = resultados[var]
        
        print(f"\n{var}:")
        
        # Detecções
        n_deteccoes = sum(res['deteccoes'])
        print(f"  Total de detecções: {n_deteccoes}")
        
        if any(res['deteccoes']):
            # Primeira detecção
            idx_primeira = np.argmax(res['deteccoes'])
            data_primeira = df['DATA'].iloc[idx_primeira]
            dias_apos = (data_primeira - data_pandemia).days
            
            print(f"  Primeira detecção: {data_primeira.strftime('%Y-%m-%d')}")
            print(f"  Dias após pandemia: {dias_apos}")
            
            # Falsos positivos
            falsos_pos = sum(res['deteccoes'][:idx_pandemia])
            print(f"  Falsos positivos (pré-pandemia): {falsos_pos}")
        else:
            print("  Nenhum drift detectado")
        
        # P-valores médios
        p_val_pre = np.mean(res['p_valores'][:idx_pandemia])
        p_val_pos = np.mean(res['p_valores'][idx_pandemia:])
        print(f"  P-valor médio pré-pandemia: {p_val_pre:.3f}")
        print(f"  P-valor médio pós-pandemia: {p_val_pos:.3f}")

# =============================================================================
# 4. ANÁLISE MULTIVARIADA SIMPLES
# =============================================================================

def analisar_multivariada(df, variaveis=['SAQUE', 'SAQUE_CEI', 'DEPOSITO', 'DEP_CEI']):
    """
    Análise multivariada simplificada
    """
    detector = DetectorConformalSimples(alpha=0.05, epsilon=0.92)
    
    n = len(df)
    scores_multi = np.zeros(n)
    p_valores_multi = np.zeros(n)
    
    # Para cada observação
    for i in range(n):
        if i < detector.janela_calibracao:
            scores_multi[i] = 0
            p_valores_multi[i] = 1.0
        else:
            # Calcular score multivariado (norma dos scores individuais)
            scores_vars = []
            
            for var in variaveis:
                inicio = max(0, i - detector.janela_calibracao)
                historico = df.iloc[inicio:i][var].values
                valor_atual = df.iloc[i][var]
                
                score = detector.calcular_score(valor_atual, historico)
                scores_vars.append(score)
            
            # Score multivariado
            scores_multi[i] = np.linalg.norm(scores_vars)
            
            # P-valor
            scores_hist = scores_multi[inicio:i]
            p_valores_multi[i] = detector.calcular_pvalor(scores_multi[i], scores_hist)
    
    # Martingale
    martingale_multi = np.ones(n)
    if n > detector.janela_calibracao:
        mart_calc = detector.power_martingale(p_valores_multi[detector.janela_calibracao:])
        martingale_multi[detector.janela_calibracao:] = mart_calc
    
    # Visualizar
    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8), sharex=True)
    
    data_pandemia = pd.to_datetime('2020-03-01')
    
    # Martingale
    ax1.semilogy(df['DATA'], martingale_multi, 'purple', linewidth=2)
    ax1.axhline(detector.threshold, color='red', linestyle='--', label='Threshold')
    ax1.axvline(data_pandemia, color='black', linestyle='--', alpha=0.5, label='Pandemia')
    ax1.set_title('Análise Multivariada - Power Martingale')
    ax1.set_ylabel('Martingale (log)')
    ax1.legend()
    ax1.grid(True, alpha=0.3)
    
    # P-valores
    ax2.plot(df['DATA'], p_valores_multi, 'green', alpha=0.7)
    ax2.axhline(0.05, color='red', linestyle=':', label='α=0.05')
    ax2.axvline(data_pandemia, color='black', linestyle='--', alpha=0.5)
    ax2.set_title('P-valores Multivariados')
    ax2.set_xlabel('Data')
    ax2.set_ylabel('P-valor')
    ax2.set_ylim(0, 1.1)
    ax2.legend()
    ax2.grid(True, alpha=0.3)
    
    plt.tight_layout()
    plt.savefig('drift_numerarios_multivariada.png', dpi=300, bbox_inches='tight')
    plt.show()
    
    return {
        'scores': scores_multi,
        'p_valores': p_valores_multi,
        'martingale': martingale_multi,
        'deteccoes': martingale_multi > detector.threshold
    }

# =============================================================================
# EXEMPLO DE USO
# =============================================================================

if __name__ == "__main__":
    # Para executar:
    # df_agencia, resultados = analisar_drift_numerarios('previsoes_numerario_pre_pos_pandemia.csv')
    
    print("\nScript de detecção de drift para Numerários")
    print("Use: df_agencia, resultados = analisar_drift_numerarios('arquivo.csv', agencia_id)")
