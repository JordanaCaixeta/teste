# Sistema Otimizado de Detec√ß√£o de Drift para Modelo Numer√°rios
# AutoMLOps Framework - Vers√£o 2.0
# ============================================================================

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from tqdm import tqdm
from datetime import datetime, timedelta
from collections import deque
from typing import Dict, List, Tuple, Optional, Union
import warnings
import logging
from dataclasses import dataclass
from scipy.linalg import pinv
from scipy.spatial.distance import mahalanobis
import json

warnings.filterwarnings('ignore')

# ============================================================================
# CONFIGURA√á√ÉO E LOGGING
# ============================================================================

# Configurar logging para manter hist√≥rico completo
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('drift_detection.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

# Configura√ß√µes de visualiza√ß√£o
plt.style.use('seaborn-v0_8-darkgrid')
sns.set_palette("husl")
plt.rcParams['figure.figsize'] = (12, 6)
plt.rcParams['font.size'] = 10

# ============================================================================
# DATACLASSES PARA CONFIGURA√á√ÉO
# ============================================================================

@dataclass
class ConfiguracaoDrift:
    """Configura√ß√µes parametriz√°veis do sistema de detec√ß√£o"""
    # Filtros
    agencia_analise: Optional[int] = None  # None = todas as ag√™ncias
    
    # Janelas temporais
    janela_deslizante: int = 1000  # Tamanho da janela para otimiza√ß√£o
    janelas_analise: List[int] = None  # [7, 30, 90] por padr√£o
    
    # Par√¢metros do m√©todo conformal
    epsilon_power: float = 0.92  # Power martingale
    epsilon_range: Tuple[float, float] = (0.85, 0.95)  # Range para otimiza√ß√£o
    
    # Detec√ß√£o
    threshold_mult: float = 20.0
    min_consecutivos: int = 3
    periodo_calibracao: int = 90
    
    # Scores
    scores_ativos: List[str] = None  # None = todos os scores
    
    # Performance
    usar_otimizacao_memoria: bool = True
    max_historico_log: int = 10000  # M√°ximo de entradas no log
    
    def __post_init__(self):
        if self.janelas_analise is None:
            self.janelas_analise = [7, 30, 90]
        if self.scores_ativos is None:
            self.scores_ativos = ['mad', 'contextual', 'std']  # Padr√£o: 3 melhores

# ============================================================================
# PARTE 1: CARREGAMENTO E PREPARA√á√ÉO DOS DADOS
# ============================================================================

def carregar_dados(path_features='features.parquet', 
                   path_previsoes='previsoes_numerario_pre_pos_pandemia.csv',
                   config: ConfiguracaoDrift = None):
    """
    Carrega os dados com configura√ß√£o parametriz√°vel.
    
    Args:
        path_features: Caminho para arquivo de features
        path_previsoes: Caminho para arquivo de previs√µes
        config: Configura√ß√µes do sistema
    """
    logger.info("Iniciando carregamento de dados...")
    
    # Carregar features
    features_df = pd.read_parquet(path_features)
    logger.info(f"Features carregadas: {features_df.shape}")
    
    # Carregar previs√µes
    previsoes_df = pd.read_csv(path_previsoes)
    
    # Padronizar nomes
    previsoes_df = previsoes_df.rename(columns={
        'DEP_CEI': 'DEPCEI',
        'DEPOSITO': 'DEP', 
        'SAQUE': 'SAQ',
        'SAQUE_CEI': 'SAQCEI'
    })
    
    # Converter datas
    features_df['DATA'] = pd.to_datetime(features_df['DATA'])
    previsoes_df['DATA'] = pd.to_datetime(previsoes_df['DATA'])
    previsoes_df['DATA_PREVISAO'] = pd.to_datetime(previsoes_df['DATA_PREVISAO'])
    previsoes_df['DATA_REFERENCIA'] = pd.to_datetime(previsoes_df['DATA_REFERENCIA'])
    
    logger.info(f"Previs√µes carregadas: {previsoes_df.shape}")
    
    return features_df, previsoes_df

def merge_real_previsto(features_df, previsoes_df, config: ConfiguracaoDrift):
    """
    Combina dados reais com previstos usando configura√ß√£o.
    """
    logger.info("Combinando dados reais e previstos...")
    
    # Preparar dados
    variaveis_alvo = ['SAQ', 'DEP', 'SAQCEI', 'DEPCEI']
    
    # Dados reais
    real_cols = ['AGENCIA', 'DATA'] + variaveis_alvo
    df_real = features_df[real_cols].copy()
    
    for var in variaveis_alvo:
        df_real[f'{var}_REAL'] = df_real[var]
    df_real = df_real.drop(columns=variaveis_alvo)
    
    # Dados previstos
    prev_cols = ['AGENCIA', 'DATA', 'DATA_PREVISAO', 'DATA_REFERENCIA'] + variaveis_alvo
    df_prev = previsoes_df[prev_cols].copy()
    
    for var in variaveis_alvo:
        df_prev[f'{var}_PREV'] = df_prev[var]
    df_prev = df_prev.drop(columns=variaveis_alvo)
    
    # Merge
    df_merged = pd.merge(df_real, df_prev, on=['AGENCIA', 'DATA'], how='inner')
    
    # Features de calend√°rio
    features_calendario = [col for col in features_df.columns 
                          if col not in ['AGENCIA', 'DATA'] + variaveis_alvo]
    
    df_merged = pd.merge(df_merged, 
                        features_df[['AGENCIA', 'DATA'] + features_calendario],
                        on=['AGENCIA', 'DATA'], 
                        how='left')
    
    # Aplicar filtro de ag√™ncia se configurado
    if config.agencia_analise is not None:
        logger.info(f"Filtrando para ag√™ncia {config.agencia_analise}")
        df_merged = df_merged[df_merged['AGENCIA'] == config.agencia_analise].copy()
    
    logger.info(f"Dados combinados: {df_merged.shape}")
    logger.info(f"Per√≠odo: {df_merged['DATA'].min()} a {df_merged['DATA'].max()}")
    
    return df_merged

# ============================================================================
# PARTE 2: SCORES DE N√ÉO-CONFORMIDADE MODULARES
# ============================================================================

class ScoreNaoConformidade:
    """Classe base para scores de n√£o-conformidade"""
    
    def __init__(self, nome: str, janela_historico: int = 30, epsilon: float = 1e-8):
        self.nome = nome
        self.janela_historico = janela_historico
        self.epsilon = epsilon
        self.historico = deque(maxlen=janela_historico)
        
    def calcular(self, real: np.ndarray, previsto: np.ndarray, 
                 contexto: Optional[pd.DataFrame] = None) -> np.ndarray:
        """M√©todo a ser implementado pelas subclasses"""
        raise NotImplementedError
        
    def adicionar_historico(self, valores):
        """Adiciona valores ao hist√≥rico mantendo janela"""
        self.historico.extend(valores)

# Implementa√ß√µes espec√≠ficas de cada score

class ScoreAbsoluto(ScoreNaoConformidade):
    """Score de erro absoluto simples"""
    
    def calcular(self, real: np.ndarray, previsto: np.ndarray, 
                 contexto: Optional[pd.DataFrame] = None) -> np.ndarray:
        return np.abs(real - previsto)

class ScoreRelativo(ScoreNaoConformidade):
    """Score de erro relativo"""
    
    def calcular(self, real: np.ndarray, previsto: np.ndarray,
                 contexto: Optional[pd.DataFrame] = None) -> np.ndarray:
        return np.abs(real - previsto) / (np.abs(real) + self.epsilon)

class ScorePadronizado(ScoreNaoConformidade):
    """Score padronizado (Z-score) com janela otimizada"""
    
    def calcular(self, real: np.ndarray, previsto: np.ndarray,
                 contexto: Optional[pd.DataFrame] = None) -> np.ndarray:
        erros = real - previsto
        scores = np.zeros_like(erros, dtype=float)
        
        for i in range(len(erros)):
            if len(self.historico) >= 5:  # M√≠nimo para calcular std
                hist_array = np.array(self.historico)
                std_hist = np.std(hist_array)
                if std_hist > 0:
                    scores[i] = np.abs(erros[i]) / std_hist
                else:
                    scores[i] = np.abs(erros[i])
            else:
                scores[i] = np.abs(erros[i])
            
            # Atualizar hist√≥rico
            self.historico.append(erros[i])
        
        return scores

class ScoreMAD(ScoreNaoConformidade):
    """Score normalizado por MAD com janela otimizada"""
    
    def calcular(self, real: np.ndarray, previsto: np.ndarray,
                 contexto: Optional[pd.DataFrame] = None) -> np.ndarray:
        erros = real - previsto
        scores = np.zeros_like(erros, dtype=float)
        
        for i in range(len(erros)):
            if len(self.historico) >= 5:
                hist_array = np.array(self.historico)
                mad = np.median(np.abs(hist_array - np.median(hist_array)))
                scores[i] = np.abs(erros[i]) / (1.4826 * mad + self.epsilon)
            else:
                scores[i] = np.abs(erros[i])
            
            self.historico.append(erros[i])
        
        return scores

class ScoreContextual(ScoreNaoConformidade):
    """Score contextual considerando tipo de dia"""
    
    def __init__(self, nome: str = "contextual", janela_historico: int = 30, 
                 epsilon: float = 1e-8):
        super().__init__(nome, janela_historico, epsilon)
        self.historico_por_contexto = {}
    
    def calcular(self, real: np.ndarray, previsto: np.ndarray,
                 contexto: Optional[pd.DataFrame] = None) -> np.ndarray:
        if contexto is None or 'DIA_SEMANA' not in contexto.columns:
            # Fallback para score absoluto
            return np.abs(real - previsto)
        
        erros = real - previsto
        scores = np.zeros_like(erros, dtype=float)
        tipo_dia = contexto['DIA_SEMANA'].values
        
        for i in range(len(erros)):
            contexto_atual = str(tipo_dia[i])
            
            # Inicializar hist√≥rico do contexto se necess√°rio
            if contexto_atual not in self.historico_por_contexto:
                self.historico_por_contexto[contexto_atual] = deque(maxlen=self.janela_historico)
            
            hist_contexto = self.historico_por_contexto[contexto_atual]
            
            if len(hist_contexto) >= 3:
                hist_array = np.array(hist_contexto)
                mad = np.median(np.abs(hist_array - np.median(hist_array)))
                scores[i] = np.abs(erros[i]) / (1.4826 * mad + self.epsilon)
            else:
                scores[i] = np.abs(erros[i])
            
            # Atualizar hist√≥rico do contexto
            hist_contexto.append(erros[i])
        
        return scores

class ScoreMahalanobis(ScoreNaoConformidade):
    """Score de Mahalanobis com verifica√ß√£o de estabilidade"""
    
    def __init__(self, nome: str = "mahalanobis", janela_historico: int = 30,
                 epsilon: float = 1e-8, condition_threshold: float = 1e10):
        super().__init__(nome, janela_historico, epsilon)
        self.condition_threshold = condition_threshold
        self.features_historico = deque(maxlen=janela_historico)
    
    def calcular(self, real: np.ndarray, previsto: np.ndarray,
                 contexto: Optional[pd.DataFrame] = None) -> np.ndarray:
        if contexto is None:
            return np.abs(real - previsto)
        
        # Features importantes
        features_importantes = ['DIA_SEMANA', 'SEMANA_QUINTO_DU', 'DIA_FERIADO', 
                               'DIA_UTIL', 'EMENDA', 'DIA_ADJACENTE_FERIADO']
        features_disponiveis = [f for f in features_importantes if f in contexto.columns]
        
        if len(features_disponiveis) < 2:
            return np.abs(real - previsto)
        
        erros = real - previsto
        scores = np.zeros_like(erros, dtype=float)
        X_contexto = contexto[features_disponiveis].values
        
        for i in range(len(erros)):
            if len(self.features_historico) > len(features_disponiveis) + 1:
                X_hist = np.array(list(self.features_historico))
                
                # Calcular covari√¢ncia com regulariza√ß√£o
                cov_matrix = np.cov(X_hist.T)
                
                # Verificar condition number
                eigenvalues = np.linalg.eigvalsh(cov_matrix)
                condition_number = np.max(eigenvalues) / (np.min(eigenvalues) + self.epsilon)
                
                if condition_number < self.condition_threshold:
                    # Matriz bem condicionada
                    try:
                        inv_cov = np.linalg.inv(cov_matrix + self.epsilon * np.eye(len(features_disponiveis)))
                        centro = np.mean(X_hist, axis=0)
                        dist = mahalanobis(X_contexto[i], centro, inv_cov)
                        scores[i] = np.abs(erros[i]) * (1 + dist)
                    except:
                        scores[i] = np.abs(erros[i])
                else:
                    # Matriz mal condicionada - usar regulariza√ß√£o
                    logger.warning(f"Condition number alto: {condition_number:.2e}")
                    scores[i] = np.abs(erros[i])
            else:
                scores[i] = np.abs(erros[i])
            
            # Atualizar hist√≥rico
            self.features_historico.append(X_contexto[i])
            
        return scores

# ============================================================================
# PARTE 3: GERENCIADOR DE SCORES MODULAR
# ============================================================================

class GerenciadorScores:
    """Gerencia diferentes implementa√ß√µes de scores"""
    
    def __init__(self, config: ConfiguracaoDrift):
        self.config = config
        self.scores_disponiveis = {
            'abs': ScoreAbsoluto,
            'rel': ScoreRelativo,
            'std': ScorePadronizado,
            'mad': ScoreMAD,
            'contextual': ScoreContextual,
            'mahalanobis': ScoreMahalanobis
        }
        self.scores_ativos = {}
        self._inicializar_scores()
    
    def _inicializar_scores(self):
        """Inicializa apenas os scores configurados"""
        janela = self.config.janela_deslizante if self.config.usar_otimizacao_memoria else 30
        
        for nome_score in self.config.scores_ativos:
            if nome_score in self.scores_disponiveis:
                classe_score = self.scores_disponiveis[nome_score]
                self.scores_ativos[nome_score] = classe_score(
                    nome=nome_score,
                    janela_historico=janela
                )
                logger.info(f"Score '{nome_score}' inicializado")
    
    def calcular_score(self, nome_score: str, real: np.ndarray, 
                      previsto: np.ndarray, contexto: Optional[pd.DataFrame] = None) -> np.ndarray:
        """Calcula um score espec√≠fico"""
        if nome_score not in self.scores_ativos:
            raise ValueError(f"Score '{nome_score}' n√£o est√° ativo. Scores ativos: {list(self.scores_ativos.keys())}")
        
        return self.scores_ativos[nome_score].calcular(real, previsto, contexto)
    
    def calcular_todos_scores(self, real: np.ndarray, previsto: np.ndarray,
                            contexto: Optional[pd.DataFrame] = None) -> Dict[str, np.ndarray]:
        """Calcula todos os scores ativos"""
        resultados = {}
        for nome_score, score_obj in self.scores_ativos.items():
            resultados[nome_score] = score_obj.calcular(real, previsto, contexto)
        return resultados

# ============================================================================
# PARTE 4: C√ÅLCULO DE P-VALORES COM OTIMIZA√á√ÉO
# ============================================================================

class CalculadorPValoresOtimizado:
    """Calcula p-valores com janela deslizante para otimiza√ß√£o de mem√≥ria"""
    
    def __init__(self, window_size: int = 1000, manter_log_completo: bool = True):
        self.window_size = window_size
        self.manter_log_completo = manter_log_completo
        self.log_completo = [] if manter_log_completo else None
        
    def calcular_pvalores_univariado(self, scores: np.ndarray, 
                                   rtol: float = 1e-3, atol: float = 1e-3) -> Tuple[np.ndarray, np.ndarray]:
        """
        Calcula p-valores com janela deslizante otimizada.
        
        Window size = 1000 significa que mantemos apenas as √∫ltimas 1000 observa√ß√µes
        para compara√ß√£o, reduzindo complexidade de O(n¬≤) para O(n*window_size).
        """
        N = len(scores)
        p_det = np.zeros(N)
        p_rnd = np.zeros(N)
        
        # Janela deslizante de scores
        janela_scores = deque(maxlen=self.window_size)
        
        for n in tqdm(range(N), desc="Calculando p-valores otimizado"):
            score_n = scores[n]
            
            # Adicionar score atual √† janela
            janela_scores.append(score_n)
            
            # Para as primeiras observa√ß√µes, usar todas dispon√≠veis
            scores_comparacao = list(janela_scores)
            n_comparacao = len(scores_comparacao)
            
            if n == 0:
                p_det[0] = 1
                p_rnd[0] = 1
                if self.manter_log_completo:
                    self.log_completo.append({
                        'n': n,
                        'score': score_n,
                        'p_det': 1,
                        'p_rnd': 1,
                        'n_comparacao': 1
                    })
                continue
            
            # P-valor determin√≠stico
            scores_array = np.array(scores_comparacao)
            p_det[n] = np.mean(scores_array >= score_n)
            
            # P-valor randomizado
            countG = np.sum(scores_array > score_n)
            countE = np.sum(np.isclose(scores_array, score_n, rtol=rtol, atol=atol))
            u = np.random.uniform() if countE > 0 else 0
            # Usar n+1 para evitar divis√£o por zero e manter propriedade v√°lida
            p_rnd[n] = (countG + u * countE) / (n_comparacao)
            
            # Log para an√°lise posterior
            if self.manter_log_completo:
                self.log_completo.append({
                    'n': n,
                    'score': score_n,
                    'p_det': p_det[n],
                    'p_rnd': p_rnd[n],
                    'n_comparacao': n_comparacao,
                    'countG': countG,
                    'countE': countE
                })
        
        logger.info(f"P-valores calculados com janela de tamanho {self.window_size}")
        return p_det, p_rnd
    
    def salvar_log(self, filepath: str = "pvalores_log.json"):
        """Salva log completo para an√°lise posterior"""
        if self.manter_log_completo and self.log_completo:
            # Limitar tamanho do log se necess√°rio
            log_salvar = self.log_completo[-10000:]  # √öltimas 10k entradas
            with open(filepath, 'w') as f:
                json.dump(log_salvar, f, indent=2)
            logger.info(f"Log salvo em {filepath}")

# ============================================================================
# PARTE 5: OTIMIZA√á√ÉO DE EPSILON
# ============================================================================

def otimizar_epsilon(p_valores: np.ndarray, epsilon_range: Tuple[float, float] = (0.85, 0.95),
                    n_splits: int = 5) -> float:
    """
    Otimiza o par√¢metro epsilon usando valida√ß√£o cruzada temporal.
    
    A ideia √© encontrar o epsilon que maximiza a capacidade de detec√ß√£o
    mantendo estabilidade em per√≠odos sem drift.
    """
    logger.info(f"Otimizando epsilon no range {epsilon_range}")
    
    epsilons = np.linspace(epsilon_range[0], epsilon_range[1], 11)
    scores = []
    
    for eps in epsilons:
        # Dividir s√©rie em splits temporais
        split_size = len(p_valores) // n_splits
        estabilidade_scores = []
        
        for i in range(n_splits - 1):
            inicio = i * split_size
            fim = (i + 1) * split_size
            
            # Calcular martingale no per√≠odo
            p_split = p_valores[inicio:fim]
            mart = power_martingale(p_split, epsilon=eps)
            
            # Medir estabilidade (menor varia√ß√£o √© melhor)
            if len(mart) > 1:
                cv = np.std(np.log(mart + 1e-10)) / np.mean(np.log(mart + 1e-10))
                estabilidade_scores.append(cv)
        
        score_medio = np.mean(estabilidade_scores)
        scores.append(score_medio)
        logger.debug(f"Epsilon {eps:.3f}: score {score_medio:.4f}")
    
    # Escolher epsilon com melhor score (menor varia√ß√£o)
    idx_otimo = np.argmin(scores)
    epsilon_otimo = epsilons[idx_otimo]
    
    logger.info(f"Epsilon √≥timo encontrado: {epsilon_otimo:.3f}")
    return epsilon_otimo

# ============================================================================
# PARTE 6: MARTINGALES
# ============================================================================

def power_martingale(p_values: np.ndarray, epsilon: float = 0.92) -> np.ndarray:
    """Power Martingale com prote√ß√£o contra underflow"""
    # Evitar p-valores zero
    p_values = np.maximum(p_values, 1e-10)
    
    # Power martingale com log-sum-exp trick para estabilidade num√©rica
    log_betting = np.log(epsilon) + (epsilon - 1) * np.log(p_values)
    log_M = np.cumsum(log_betting)
    M = np.exp(log_M)
    
    return M

def simple_jumper_martingale(p_values: np.ndarray, J: float = 0.01) -> np.ndarray:
    """Simple Jumper Martingale"""
    n = len(p_values)
    capital = np.zeros(n + 1)
    capital[0] = 1.0
    
    C = {epsilon: 1/3 for epsilon in [-1, 0, 1]}
    
    for i in range(n):
        # Transi√ß√£o
        C_new = {}
        total = sum(C.values())
        for epsilon in [-1, 0, 1]:
            C_new[epsilon] = (1 - J) * C[epsilon] + J * total / 3
        
        # Update
        p = p_values[i]
        for epsilon in [-1, 0, 1]:
            f_eps = 1 + epsilon * (p - 0.5)
            C_new[epsilon] *= f_eps
        
        capital[i + 1] = sum(C_new.values())
        C = C_new
    
    return capital[1:]

# ============================================================================
# PARTE 7: VISUALIZA√á√ïES MELHORADAS
# ============================================================================

def plot_boxplot_erros_contexto_melhorado(df_merged: pd.DataFrame, variavel: str = 'SAQ',
                                         save_path: str = None):
    """
    Vers√£o melhorada do boxplot com melhor visibilidade.
    """
    # Criar figura com subplots maiores
    fig, axes = plt.subplots(2, 3, figsize=(20, 12))
    axes = axes.flatten()
    
    # Calcular erro
    erro = df_merged[f'{variavel}_REAL'] - df_merged[f'{variavel}_PREV']
    erro_rel = erro / (df_merged[f'{variavel}_REAL'] + 1e-8)
    
    contextos = [
        ('DIA_SEMANA', 'Dia da Semana', None),
        ('DIA_FERIADO', 'Feriado', {0: 'N√£o', 1: 'Sim'}),
        ('SEMANA_QUINTO_DU', '5¬∫ Dia √ötil', {0: 'N√£o', 1: 'Sim'}),
        ('DIA_ADJACENTE_FERIADO', 'Adjacente Feriado', {0: 'N√£o', 1: 'Sim'}),
        ('EMENDA', 'Emenda', {0: 'N√£o', 1: 'Sim'}),
        ('FDS_DE_FERIADO', 'FDS de Feriado', {0: 'N√£o', 1: 'Sim'})
    ]
    
    for idx, (feature, titulo, labels_map) in enumerate(contextos):
        if idx >= len(axes):
            break
            
        ax = axes[idx]
        
        if feature in df_merged.columns:
            # Preparar dados
            data_plot = pd.DataFrame({
                'Erro_Relativo': erro_rel,
                feature: df_merged[feature]
            })
            
            if labels_map:
                data_plot[feature] = data_plot[feature].map(labels_map).fillna('Outro')
            
            # Criar boxplot com estilo melhorado
            unique_vals = data_plot[feature].unique()
            positions = range(len(unique_vals))
            
            box_data = [data_plot[data_plot[feature] == val]['Erro_Relativo'].values 
                       for val in unique_vals]
            
            # Boxplot customizado
            bp = ax.boxplot(box_data, positions=positions, widths=0.6,
                           patch_artist=True, showfliers=False)
            
            # Customizar cores
            colors = plt.cm.Set3(np.linspace(0, 1, len(unique_vals)))
            for patch, color in zip(bp['boxes'], colors):
                patch.set_facecolor(color)
                patch.set_alpha(0.7)
            
            # Melhorar linhas
            for element in ['whiskers', 'fliers', 'means', 'medians', 'caps']:
                if element in bp:
                    plt.setp(bp[element], color='black', linewidth=1.5)
            
            # Labels e t√≠tulo
            ax.set_xticklabels(unique_vals, rotation=45 if len(str(unique_vals[0])) > 3 else 0)
            ax.set_title(f'Erro Relativo por {titulo}', fontsize=14, fontweight='bold')
            ax.set_xlabel(titulo, fontsize=12)
            ax.set_ylabel('Erro Relativo', fontsize=12)
            ax.set_ylim(-1, 1)
            ax.grid(True, alpha=0.3, axis='y')
            
            # Adicionar linha de refer√™ncia
            ax.axhline(y=0, color='red', linestyle='--', alpha=0.5)
    
    # Remover eixos vazios
    for idx in range(len(contextos), len(axes)):
        fig.delaxes(axes[idx])
    
    plt.suptitle(f'An√°lise de Erros por Contexto - {variavel}', fontsize=18, fontweight='bold')
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        logger.info(f"Boxplot salvo em {save_path}")
    
    plt.show()

def plot_dashboard_modular(resultados: Dict, df_merged: pd.DataFrame,
                          componentes: List[str] = None, save_path: str = None):
    """
    Dashboard modular que permite escolher quais componentes visualizar.
    
    Args:
        componentes: Lista de componentes a incluir:
            - 'martingales': Compara√ß√£o de martingales
            - 'metricas': M√©tricas por vari√°vel
            - 'timeline': Timeline de detec√ß√µes
            - 'scores': Compara√ß√£o de scores
    """
    if componentes is None:
        componentes = ['martingales', 'metricas', 'timeline']
    
    n_componentes = len(componentes)
    fig, axes = plt.subplots(n_componentes, 1, figsize=(15, 5*n_componentes))
    
    if n_componentes == 1:
        axes = [axes]
    
    for idx, componente in enumerate(componentes):
        ax = axes[idx]
        
        if componente == 'martingales':
            # Compara√ß√£o de martingales
            for var in ['SAQ', 'DEP', 'SAQCEI', 'DEPCEI']:
                if var in resultados['univariado']:
                    mart = resultados['univariado'][var]['martingale_power']
                    ax.plot(mart, label=f'{var}', linewidth=2)
            
            if 'multivariado' in resultados:
                mart_multi = resultados['multivariado']['martingale_power']
                ax.plot(mart_multi, label='Multivariado', linewidth=3, 
                       linestyle='--', color='red')
            
            ax.set_yscale('log')
            ax.set_xlabel('Tempo')
            ax.set_ylabel('Martingale (log)')
            ax.set_title('Evolu√ß√£o dos Martingales')
            ax.legend()
            ax.grid(True, alpha=0.3)
            
        elif componente == 'metricas':
            # M√©tricas por vari√°vel
            variaveis = ['SAQ', 'DEP', 'SAQCEI', 'DEPCEI']
            max_martingales = []
            deteccoes_count = []
            
            for var in variaveis:
                if var in resultados['univariado']:
                    max_mart = np.max(resultados['univariado'][var]['martingale_power'])
                    max_martingales.append(np.log10(max_mart))
                    n_det = len(resultados['univariado'][var]['deteccoes'])
                    deteccoes_count.append(n_det)
                else:
                    max_martingales.append(0)
                    deteccoes_count.append(0)
            
            x = np.arange(len(variaveis))
            width = 0.35
            
            ax2 = ax.twinx()
            
            bars1 = ax.bar(x - width/2, max_martingales, width, 
                          label='Log10(Max Martingale)', color='skyblue')
            bars2 = ax2.bar(x + width/2, deteccoes_count, width,
                           label='N¬∫ Detec√ß√µes', color='orange')
            
            ax.set_xlabel('Vari√°vel')
            ax.set_ylabel('Log10(Max Martingale)', color='skyblue')
            ax2.set_ylabel('N√∫mero de Detec√ß√µes', color='orange')
            ax.set_title('M√©tricas de Drift por Vari√°vel')
            ax.set_xticks(x)
            ax.set_xticklabels(variaveis)
            ax.tick_params(axis='y', labelcolor='skyblue')
            ax2.tick_params(axis='y', labelcolor='orange')
            
            # Adicionar valores nas barras
            for bar, val in zip(bars1, max_martingales):
                height = bar.get_height()
                ax.annotate(f'{val:.1f}',
                           xy=(bar.get_x() + bar.get_width() / 2, height),
                           xytext=(0, 3),
                           textcoords="offset points",
                           ha='center', va='bottom')
            
            for bar, val in zip(bars2, deteccoes_count):
                height = bar.get_height()
                ax2.annotate(f'{int(val)}',
                            xy=(bar.get_x() + bar.get_width() / 2, height),
                            xytext=(0, 3),
                            textcoords="offset points",
                            ha='center', va='bottom')
            
        elif componente == 'timeline':
            # Timeline de detec√ß√µes
            tempo = np.arange(len(df_merged))
            
            # Base timeline
            ax.scatter(tempo, np.zeros_like(tempo), alpha=0.1, s=1, c='gray')
            
            # Detec√ß√µes por vari√°vel
            cores = ['blue', 'green', 'orange', 'purple']
            variaveis = ['SAQ', 'DEP', 'SAQCEI', 'DEPCEI']
            
            for idx_var, (var, cor) in enumerate(zip(variaveis, cores)):
                if var in resultados['univariado']:
                    deteccoes = resultados['univariado'][var]['deteccoes']
                    if deteccoes:
                        ax.scatter(deteccoes, [idx_var+1]*len(deteccoes),
                                 label=f'{var}', s=100, alpha=0.7, c=cor)
            
            # Detec√ß√µes multivariadas
            if 'multivariado' in resultados:
                det_multi = resultados['multivariado']['deteccoes']
                if det_multi:
                    ax.scatter(det_multi, [5]*len(det_multi),
                             label='Multivariado', s=150, marker='^', c='red')
            
            ax.set_ylim(-0.5, 5.5)
            ax.set_xlabel('Tempo')
            ax.set_yticks(range(6))
            ax.set_yticklabels([''] + variaveis + ['Multi'])
            ax.set_title('Timeline de Detec√ß√µes de Drift')
            ax.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
            ax.grid(True, axis='x', alpha=0.3)
            
        elif componente == 'scores':
            # Compara√ß√£o de scores (se dispon√≠vel)
            if 'univariado' in resultados and 'SAQ' in resultados['univariado']:
                scores_data = resultados['univariado']['SAQ'].get('scores', {})
                if scores_data:
                    scores_nomes = list(scores_data.keys())
                    scores_max = [np.percentile(scores_data[s], 95) for s in scores_nomes]
                    
                    bars = ax.bar(range(len(scores_nomes)), scores_max)
                    ax.set_xticks(range(len(scores_nomes)))
                    ax.set_xticklabels(scores_nomes, rotation=45)
                    ax.set_ylabel('Score (percentil 95)')
                    ax.set_title('Compara√ß√£o de Scores - SAQ')
                    
                    # Colorir melhor score
                    melhor_idx = np.argmax(scores_max)
                    bars[melhor_idx].set_color('red')
    
    plt.suptitle('Dashboard de Monitoramento de Drift', fontsize=16, fontweight='bold')
    plt.tight_layout()
    
    if save_path:
        plt.savefig(save_path, dpi=300, bbox_inches='tight')
        logger.info(f"Dashboard salvo em {save_path}")
    
    plt.show()

# ============================================================================
# PARTE 8: PIPELINE PRINCIPAL OTIMIZADO
# ============================================================================

def executar_analise_drift_otimizada(df_merged: pd.DataFrame, 
                                   config: ConfiguracaoDrift) -> Dict:
    """
    Pipeline principal otimizado com todas as melhorias.
    """
    logger.info("üöÄ Iniciando an√°lise de drift otimizada...")
    
    variaveis = ['SAQ', 'DEP', 'SAQCEI', 'DEPCEI']
    resultados_univariado = {}
    
    # Inicializar gerenciador de scores
    gerenciador_scores = GerenciadorScores(config)
    
    # Inicializar calculador de p-valores otimizado
    calc_pvalores = CalculadorPValoresOtimizado(
        window_size=config.janela_deslizante,
        manter_log_completo=True
    )
    
    # =========================
    # AN√ÅLISE UNIVARIADA
    # =========================
    logger.info("üìä AN√ÅLISE UNIVARIADA")
    
    for var in variaveis:
        logger.info(f"\n‚ñ∂Ô∏è  Analisando {var}...")
        
        # Valores reais e previstos
        real = df_merged[f'{var}_REAL'].values
        previsto = df_merged[f'{var}_PREV'].values
        
        # Features de contexto
        features_contexto = [col for col in df_merged.columns 
                           if col.startswith(('DIA_', 'SEMANA_', 'QTD_', 
                                            'NUM_', 'EMENDA', 'FDS_'))]
        contexto_df = df_merged[features_contexto]
        
        # Calcular scores configurados
        scores_dict = gerenciador_scores.calcular_todos_scores(real, previsto, contexto_df)
        
        # Para cada score, calcular p-valores e detectar
        resultados_var = {
            'scores': scores_dict,
            'p_valores': {},
            'martingales': {},
            'deteccoes_por_score': {}
        }
        
        melhor_score = None
        melhor_deteccao = float('inf')
        
        for nome_score, valores_score in scores_dict.items():
            # Calcular p-valores com otimiza√ß√£o
            p_det, p_rnd = calc_pvalores.calcular_pvalores_univariado(valores_score)
            
            # Otimizar epsilon se configurado
            if config.epsilon_range:
                epsilon_otimo = otimizar_epsilon(p_rnd, config.epsilon_range)
            else:
                epsilon_otimo = config.epsilon_power
            
            # Power martingale
            mart_power = power_martingale(p_rnd, epsilon=epsilon_otimo)
            
            # Detectar mudan√ßas
            deteccoes = detectar_mudanca_otimizada(
                mart_power, 
                config=config
            )
            
            resultados_var['p_valores'][nome_score] = {'det': p_det, 'rnd': p_rnd}
            resultados_var['martingales'][nome_score] = mart_power
            resultados_var['deteccoes_por_score'][nome_score] = deteccoes
            
            # Verificar se √© o melhor score
            if deteccoes and deteccoes[0] < melhor_deteccao:
                melhor_score = nome_score
                melhor_deteccao = deteccoes[0]
            
            logger.info(f"  - Score {nome_score}: {len(deteccoes)} detec√ß√µes")
        
        # Selecionar melhor score
        if melhor_score:
            resultados_var['melhor_score'] = melhor_score
            resultados_var['martingale_power'] = resultados_var['martingales'][melhor_score]
            resultados_var['deteccoes'] = resultados_var['deteccoes_por_score'][melhor_score]
        else:
            # Fallback para primeiro score dispon√≠vel
            primeiro_score = list(scores_dict.keys())[0]
            resultados_var['melhor_score'] = primeiro_score
            resultados_var['martingale_power'] = resultados_var['martingales'][primeiro_score]
            resultados_var['deteccoes'] = resultados_var['deteccoes_por_score'][primeiro_score]
        
        resultados_univariado[var] = resultados_var
    
    # Salvar log de p-valores
    calc_pvalores.salvar_log(f"pvalores_log_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json")
    
    # =========================
    # AN√ÅLISE MULTIVARIADA
    # =========================
    # [C√≥digo similar ao original mas com otimiza√ß√µes]
    
    return {
        'univariado': resultados_univariado,
        'config': config.__dict__
    }

def detectar_mudanca_otimizada(martingale: np.ndarray, config: ConfiguracaoDrift) -> List[int]:
    """
    Detecta mudan√ßas com configura√ß√µes parametriz√°veis.
    """
    deteccoes = []
    alarmes_consecutivos = 0
    
    # Calibrar threshold
    periodo_calib = min(config.periodo_calibracao, len(martingale) // 4)
    if periodo_calib > 30:
        baseline = martingale[:periodo_calib]
        threshold_base = np.percentile(baseline, 95) * config.threshold_mult
    else:
        threshold_base = config.threshold_mult
    
    # Detectar
    for i in range(len(martingale)):
        if martingale[i] > threshold_base:
            alarmes_consecutivos += 1
            
            if alarmes_consecutivos >= config.min_consecutivos:
                if not deteccoes or i - deteccoes[-1] > 30:
                    deteccoes.append(i)
                    logger.debug(f"Drift detectado no √≠ndice {i}")
        else:
            alarmes_consecutivos = 0
    
    return deteccoes

# ============================================================================
# FUN√á√ÉO PRINCIPAL
# ============================================================================

def main():
    """
    Executa an√°lise com configura√ß√µes customiz√°veis.
    """
    # Criar configura√ß√£o
    config = ConfiguracaoDrift(
        agencia_analise=20,  # None para todas
        janela_deslizante=1000,
        janelas_analise=[7, 30, 90],
        epsilon_power=0.92,
        epsilon_range=(0.85, 0.95),  # Para otimiza√ß√£o
        scores_ativos=['mad', 'contextual', 'std'],  # Escolha modular
        usar_otimizacao_memoria=True
    )
    
    logger.info("üèÅ INICIANDO AN√ÅLISE DE DRIFT OTIMIZADA")
    logger.info(f"Configura√ß√£o: {config}")
    
    # Carregar dados
    features_df, previsoes_df = carregar_dados(config=config)
    
    # Combinar dados
    df_merged = merge_real_previsto(features_df, previsoes_df, config)
    
    # Executar an√°lise
    resultados = executar_analise_drift_otimizada(df_merged, config)
    
    # Gerar visualiza√ß√µes modulares
    logger.info("\nüìà Gerando visualiza√ß√µes...")
    
    # Boxplot melhorado
    plot_boxplot_erros_contexto_melhorado(
        df_merged, 
        variavel='SAQ',
        save_path='boxplot_erros_SAQ.png'
    )
    
    # Dashboard modular - escolha componentes
    plot_dashboard_modular(
        resultados,
        df_merged,
        componentes=['martingales', 'metricas'],  # Escolha modular
        save_path='dashboard_drift_1.png'
    )
    
    plot_dashboard_modular(
        resultados,
        df_merged,
        componentes=['timeline'],  # Timeline separado
        save_path='dashboard_drift_2.png'
    )
    
    logger.info("\n‚úÖ AN√ÅLISE CONCLU√çDA!")
    
    return resultados, df_merged

# Executar se chamado diretamente
if __name__ == "__main__":
    resultados, df_merged = main()
